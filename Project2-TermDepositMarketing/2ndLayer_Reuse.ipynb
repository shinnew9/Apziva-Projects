{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shinnew9/Apziva-Projects/blob/main/Project2-TermDepositMarketing/2ndLayer_Reuse.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Liw8RT6LDXLh"
      },
      "source": [
        "Report f2score, and write conclusion for the 2nd layer. And then let's start the next layer.\n",
        "\n",
        "3rd layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TrdefyNfBDR8",
        "outputId": "1f53e878-6697-4529-b977-921885300681"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VvWDAlg83t_W",
        "outputId": "d771641f-0e76-42d2-93a6-4c87ef1cc49d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.1.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.14.0-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (24.1)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.36)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.6)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.2)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.3.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n",
            "Downloading optuna-4.1.0-py3-none-any.whl (364 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m364.4/364.4 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.14.0-py3-none-any.whl (233 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.5/233.5 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Downloading Mako-1.3.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Mako, colorlog, alembic, optuna\n",
            "Successfully installed Mako-1.3.6 alembic-1.14.0 colorlog-6.9.0 optuna-4.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fImpso78BZou"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "\n",
        "# Warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# EDA\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Models\n",
        "# from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "# from sklearn.compose import ColumnTransformer\n",
        "from sklearn.model_selection import train_test_split\n",
        "# from collections import Counter\n",
        "\n",
        "# 2nd layer\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.linear_model import SGDClassifier, Perceptron\n",
        "from sklearn.svm import SVC\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "from imblearn.over_sampling import SMOTE  # We use imbalanced-learn library.\n",
        "from imblearn.combine import SMOTETomek,SMOTEENN\n",
        "from imblearn.under_sampling import TomekLinks\n",
        "\n",
        "# Applying OpTuna\n",
        "import optuna\n",
        "\n",
        "# 3rd layer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import KMeans\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.cluster.hierarchy import dendrogram, linkage\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "\n",
        "# Validation\n",
        "from sklearn.metrics import recall_score, classification_report, confusion_matrix, accuracy_score, precision_score, f1_score, fbeta_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "cF9BW0aABkgp",
        "outputId": "c5cf5a8e-7903-4c87-a501-7944c958c366"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 40000,\n  \"fields\": [\n    {\n      \"column\": \"age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9,\n        \"min\": 19,\n        \"max\": 95,\n        \"num_unique_values\": 70,\n        \"samples\": [\n          36,\n          58,\n          68\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"job\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 12,\n        \"samples\": [\n          \"housemaid\",\n          \"unemployed\",\n          \"management\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"marital\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"married\",\n          \"single\",\n          \"divorced\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"education\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"secondary\",\n          \"primary\",\n          \"tertiary\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"default\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"yes\",\n          \"no\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"balance\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2903,\n        \"min\": -8019,\n        \"max\": 102127,\n        \"num_unique_values\": 6849,\n        \"samples\": [\n          13711,\n          5745\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"housing\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"no\",\n          \"yes\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"loan\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"yes\",\n          \"no\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"contact\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"unknown\",\n          \"cellular\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"day\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8,\n        \"min\": 1,\n        \"max\": 31,\n        \"num_unique_values\": 31,\n        \"samples\": [\n          1,\n          27\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"month\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 11,\n        \"samples\": [\n          \"nov\",\n          \"may\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"duration\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 259,\n        \"min\": 0,\n        \"max\": 4918,\n        \"num_unique_values\": 1535,\n        \"samples\": [\n          856,\n          1467\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"campaign\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 1,\n        \"max\": 63,\n        \"num_unique_values\": 48,\n        \"samples\": [\n          41,\n          27\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"y\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"yes\",\n          \"no\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-e928955c-5c27-4181-9712-1a59def948ed\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>job</th>\n",
              "      <th>marital</th>\n",
              "      <th>education</th>\n",
              "      <th>default</th>\n",
              "      <th>balance</th>\n",
              "      <th>housing</th>\n",
              "      <th>loan</th>\n",
              "      <th>contact</th>\n",
              "      <th>day</th>\n",
              "      <th>month</th>\n",
              "      <th>duration</th>\n",
              "      <th>campaign</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>58</td>\n",
              "      <td>management</td>\n",
              "      <td>married</td>\n",
              "      <td>tertiary</td>\n",
              "      <td>no</td>\n",
              "      <td>2143</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>unknown</td>\n",
              "      <td>5</td>\n",
              "      <td>may</td>\n",
              "      <td>261</td>\n",
              "      <td>1</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>44</td>\n",
              "      <td>technician</td>\n",
              "      <td>single</td>\n",
              "      <td>secondary</td>\n",
              "      <td>no</td>\n",
              "      <td>29</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>unknown</td>\n",
              "      <td>5</td>\n",
              "      <td>may</td>\n",
              "      <td>151</td>\n",
              "      <td>1</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>33</td>\n",
              "      <td>entrepreneur</td>\n",
              "      <td>married</td>\n",
              "      <td>secondary</td>\n",
              "      <td>no</td>\n",
              "      <td>2</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>unknown</td>\n",
              "      <td>5</td>\n",
              "      <td>may</td>\n",
              "      <td>76</td>\n",
              "      <td>1</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>47</td>\n",
              "      <td>blue-collar</td>\n",
              "      <td>married</td>\n",
              "      <td>unknown</td>\n",
              "      <td>no</td>\n",
              "      <td>1506</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>unknown</td>\n",
              "      <td>5</td>\n",
              "      <td>may</td>\n",
              "      <td>92</td>\n",
              "      <td>1</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>33</td>\n",
              "      <td>unknown</td>\n",
              "      <td>single</td>\n",
              "      <td>unknown</td>\n",
              "      <td>no</td>\n",
              "      <td>1</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>unknown</td>\n",
              "      <td>5</td>\n",
              "      <td>may</td>\n",
              "      <td>198</td>\n",
              "      <td>1</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39995</th>\n",
              "      <td>53</td>\n",
              "      <td>technician</td>\n",
              "      <td>married</td>\n",
              "      <td>tertiary</td>\n",
              "      <td>no</td>\n",
              "      <td>395</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>cellular</td>\n",
              "      <td>3</td>\n",
              "      <td>jun</td>\n",
              "      <td>107</td>\n",
              "      <td>1</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39996</th>\n",
              "      <td>30</td>\n",
              "      <td>management</td>\n",
              "      <td>single</td>\n",
              "      <td>tertiary</td>\n",
              "      <td>no</td>\n",
              "      <td>3340</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>cellular</td>\n",
              "      <td>3</td>\n",
              "      <td>jun</td>\n",
              "      <td>238</td>\n",
              "      <td>3</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39997</th>\n",
              "      <td>54</td>\n",
              "      <td>admin</td>\n",
              "      <td>divorced</td>\n",
              "      <td>secondary</td>\n",
              "      <td>no</td>\n",
              "      <td>200</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>cellular</td>\n",
              "      <td>3</td>\n",
              "      <td>jun</td>\n",
              "      <td>170</td>\n",
              "      <td>1</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39998</th>\n",
              "      <td>34</td>\n",
              "      <td>management</td>\n",
              "      <td>married</td>\n",
              "      <td>tertiary</td>\n",
              "      <td>no</td>\n",
              "      <td>1047</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>cellular</td>\n",
              "      <td>3</td>\n",
              "      <td>jun</td>\n",
              "      <td>342</td>\n",
              "      <td>1</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39999</th>\n",
              "      <td>38</td>\n",
              "      <td>technician</td>\n",
              "      <td>married</td>\n",
              "      <td>secondary</td>\n",
              "      <td>no</td>\n",
              "      <td>1442</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>cellular</td>\n",
              "      <td>3</td>\n",
              "      <td>jun</td>\n",
              "      <td>113</td>\n",
              "      <td>1</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>40000 rows × 14 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e928955c-5c27-4181-9712-1a59def948ed')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e928955c-5c27-4181-9712-1a59def948ed button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e928955c-5c27-4181-9712-1a59def948ed');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6da0a402-9ff3-4b47-84a3-7e8b88f5a462\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6da0a402-9ff3-4b47-84a3-7e8b88f5a462')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6da0a402-9ff3-4b47-84a3-7e8b88f5a462 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_8b0de4a4-9c49-4292-92d6-7bc194fe1e9b\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_8b0de4a4-9c49-4292-92d6-7bc194fe1e9b button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "       age           job   marital  education default  balance housing loan  \\\n",
              "0       58    management   married   tertiary      no     2143     yes   no   \n",
              "1       44    technician    single  secondary      no       29     yes   no   \n",
              "2       33  entrepreneur   married  secondary      no        2     yes  yes   \n",
              "3       47   blue-collar   married    unknown      no     1506     yes   no   \n",
              "4       33       unknown    single    unknown      no        1      no   no   \n",
              "...    ...           ...       ...        ...     ...      ...     ...  ...   \n",
              "39995   53    technician   married   tertiary      no      395      no   no   \n",
              "39996   30    management    single   tertiary      no     3340      no   no   \n",
              "39997   54         admin  divorced  secondary      no      200      no   no   \n",
              "39998   34    management   married   tertiary      no     1047      no   no   \n",
              "39999   38    technician   married  secondary      no     1442     yes   no   \n",
              "\n",
              "        contact  day month  duration  campaign    y  \n",
              "0       unknown    5   may       261         1   no  \n",
              "1       unknown    5   may       151         1   no  \n",
              "2       unknown    5   may        76         1   no  \n",
              "3       unknown    5   may        92         1   no  \n",
              "4       unknown    5   may       198         1   no  \n",
              "...         ...  ...   ...       ...       ...  ...  \n",
              "39995  cellular    3   jun       107         1   no  \n",
              "39996  cellular    3   jun       238         3  yes  \n",
              "39997  cellular    3   jun       170         1  yes  \n",
              "39998  cellular    3   jun       342         1   no  \n",
              "39999  cellular    3   jun       113         1   no  \n",
              "\n",
              "[40000 rows x 14 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Read dataset\n",
        "df = pd.read_csv('/content/drive/MyDrive/Apziva/TermDepositMarketing/term-deposit-marketing-2020.csv')\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AP7xxM-zBqoP"
      },
      "source": [
        "## Models - 3 layers\n",
        "\n",
        "1. 1st Layer: A layer to predict which of the potential customers we should make calls to (haven't make any calls yet,can't use any call-related features like duration, campaign, month of the call and etc).\n",
        "2. 2nd Layer: A layer to predict which of the customers we should keep calling to. This means calls have already been made, I can use call-related data, to predict which of the customers we should keep making calls to. (precision for class 1)\n",
        "\n",
        "They do not directly affect each other\n",
        "3. 3rd Layer: Train both with the unsupervised model, to understand who those customers are and filtered the non-subscribers. The goal is to segment the subscribers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UdR9t_64Bt4J",
        "outputId": "0a42ca92-f2b6-4d55-9eea-873ffab6d327"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4065\n"
          ]
        }
      ],
      "source": [
        "seed = random.randint(1000, 9999)\n",
        "print(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "GwFSwkOnJfyO",
        "outputId": "9eef50cd-7a96-47c8-ee7a-b8936a45f115"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df_copy\",\n  \"rows\": 40000,\n  \"fields\": [\n    {\n      \"column\": \"age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9,\n        \"min\": 19,\n        \"max\": 95,\n        \"num_unique_values\": 70,\n        \"samples\": [\n          36,\n          58,\n          68\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"job\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 12,\n        \"samples\": [\n          \"housemaid\",\n          \"unemployed\",\n          \"management\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"marital\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"married\",\n          \"single\",\n          \"divorced\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"education\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"secondary\",\n          \"primary\",\n          \"tertiary\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"default\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"yes\",\n          \"no\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"balance\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2903,\n        \"min\": -8019,\n        \"max\": 102127,\n        \"num_unique_values\": 6849,\n        \"samples\": [\n          13711,\n          5745\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"housing\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"no\",\n          \"yes\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"loan\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"yes\",\n          \"no\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"contact\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"unknown\",\n          \"cellular\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"day\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8,\n        \"min\": 1,\n        \"max\": 31,\n        \"num_unique_values\": 31,\n        \"samples\": [\n          1,\n          27\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"month\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 11,\n        \"samples\": [\n          \"nov\",\n          \"may\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"duration\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 259,\n        \"min\": 0,\n        \"max\": 4918,\n        \"num_unique_values\": 1535,\n        \"samples\": [\n          856,\n          1467\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"campaign\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 1,\n        \"max\": 63,\n        \"num_unique_values\": 48,\n        \"samples\": [\n          41,\n          27\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"y\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"yes\",\n          \"no\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df_copy"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-a37a3d2f-0edd-4bf0-9d9b-e46ace0e0176\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>job</th>\n",
              "      <th>marital</th>\n",
              "      <th>education</th>\n",
              "      <th>default</th>\n",
              "      <th>balance</th>\n",
              "      <th>housing</th>\n",
              "      <th>loan</th>\n",
              "      <th>contact</th>\n",
              "      <th>day</th>\n",
              "      <th>month</th>\n",
              "      <th>duration</th>\n",
              "      <th>campaign</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>58</td>\n",
              "      <td>management</td>\n",
              "      <td>married</td>\n",
              "      <td>tertiary</td>\n",
              "      <td>no</td>\n",
              "      <td>2143</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>unknown</td>\n",
              "      <td>5</td>\n",
              "      <td>may</td>\n",
              "      <td>261</td>\n",
              "      <td>1</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>44</td>\n",
              "      <td>technician</td>\n",
              "      <td>single</td>\n",
              "      <td>secondary</td>\n",
              "      <td>no</td>\n",
              "      <td>29</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>unknown</td>\n",
              "      <td>5</td>\n",
              "      <td>may</td>\n",
              "      <td>151</td>\n",
              "      <td>1</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>33</td>\n",
              "      <td>entrepreneur</td>\n",
              "      <td>married</td>\n",
              "      <td>secondary</td>\n",
              "      <td>no</td>\n",
              "      <td>2</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>unknown</td>\n",
              "      <td>5</td>\n",
              "      <td>may</td>\n",
              "      <td>76</td>\n",
              "      <td>1</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>47</td>\n",
              "      <td>blue-collar</td>\n",
              "      <td>married</td>\n",
              "      <td>unknown</td>\n",
              "      <td>no</td>\n",
              "      <td>1506</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>unknown</td>\n",
              "      <td>5</td>\n",
              "      <td>may</td>\n",
              "      <td>92</td>\n",
              "      <td>1</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>33</td>\n",
              "      <td>unknown</td>\n",
              "      <td>single</td>\n",
              "      <td>unknown</td>\n",
              "      <td>no</td>\n",
              "      <td>1</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>unknown</td>\n",
              "      <td>5</td>\n",
              "      <td>may</td>\n",
              "      <td>198</td>\n",
              "      <td>1</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39995</th>\n",
              "      <td>53</td>\n",
              "      <td>technician</td>\n",
              "      <td>married</td>\n",
              "      <td>tertiary</td>\n",
              "      <td>no</td>\n",
              "      <td>395</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>cellular</td>\n",
              "      <td>3</td>\n",
              "      <td>jun</td>\n",
              "      <td>107</td>\n",
              "      <td>1</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39996</th>\n",
              "      <td>30</td>\n",
              "      <td>management</td>\n",
              "      <td>single</td>\n",
              "      <td>tertiary</td>\n",
              "      <td>no</td>\n",
              "      <td>3340</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>cellular</td>\n",
              "      <td>3</td>\n",
              "      <td>jun</td>\n",
              "      <td>238</td>\n",
              "      <td>3</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39997</th>\n",
              "      <td>54</td>\n",
              "      <td>admin</td>\n",
              "      <td>divorced</td>\n",
              "      <td>secondary</td>\n",
              "      <td>no</td>\n",
              "      <td>200</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>cellular</td>\n",
              "      <td>3</td>\n",
              "      <td>jun</td>\n",
              "      <td>170</td>\n",
              "      <td>1</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39998</th>\n",
              "      <td>34</td>\n",
              "      <td>management</td>\n",
              "      <td>married</td>\n",
              "      <td>tertiary</td>\n",
              "      <td>no</td>\n",
              "      <td>1047</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>cellular</td>\n",
              "      <td>3</td>\n",
              "      <td>jun</td>\n",
              "      <td>342</td>\n",
              "      <td>1</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39999</th>\n",
              "      <td>38</td>\n",
              "      <td>technician</td>\n",
              "      <td>married</td>\n",
              "      <td>secondary</td>\n",
              "      <td>no</td>\n",
              "      <td>1442</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>cellular</td>\n",
              "      <td>3</td>\n",
              "      <td>jun</td>\n",
              "      <td>113</td>\n",
              "      <td>1</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>40000 rows × 14 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a37a3d2f-0edd-4bf0-9d9b-e46ace0e0176')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a37a3d2f-0edd-4bf0-9d9b-e46ace0e0176 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a37a3d2f-0edd-4bf0-9d9b-e46ace0e0176');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-70a0d558-b2c2-44b5-a986-921331cf2460\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-70a0d558-b2c2-44b5-a986-921331cf2460')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-70a0d558-b2c2-44b5-a986-921331cf2460 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_ef1f66cf-a889-4992-b13c-c43209ac5496\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_copy')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_ef1f66cf-a889-4992-b13c-c43209ac5496 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_copy');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "       age           job   marital  education default  balance housing loan  \\\n",
              "0       58    management   married   tertiary      no     2143     yes   no   \n",
              "1       44    technician    single  secondary      no       29     yes   no   \n",
              "2       33  entrepreneur   married  secondary      no        2     yes  yes   \n",
              "3       47   blue-collar   married    unknown      no     1506     yes   no   \n",
              "4       33       unknown    single    unknown      no        1      no   no   \n",
              "...    ...           ...       ...        ...     ...      ...     ...  ...   \n",
              "39995   53    technician   married   tertiary      no      395      no   no   \n",
              "39996   30    management    single   tertiary      no     3340      no   no   \n",
              "39997   54         admin  divorced  secondary      no      200      no   no   \n",
              "39998   34    management   married   tertiary      no     1047      no   no   \n",
              "39999   38    technician   married  secondary      no     1442     yes   no   \n",
              "\n",
              "        contact  day month  duration  campaign    y  \n",
              "0       unknown    5   may       261         1   no  \n",
              "1       unknown    5   may       151         1   no  \n",
              "2       unknown    5   may        76         1   no  \n",
              "3       unknown    5   may        92         1   no  \n",
              "4       unknown    5   may       198         1   no  \n",
              "...         ...  ...   ...       ...       ...  ...  \n",
              "39995  cellular    3   jun       107         1   no  \n",
              "39996  cellular    3   jun       238         3  yes  \n",
              "39997  cellular    3   jun       170         1  yes  \n",
              "39998  cellular    3   jun       342         1   no  \n",
              "39999  cellular    3   jun       113         1   no  \n",
              "\n",
              "[40000 rows x 14 columns]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_copy = df.copy()\n",
        "df_copy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdsFyRpn0gDW"
      },
      "source": [
        "### Train_test_split for Layer2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 821
        },
        "id": "V8h9Uv38Cm95",
        "outputId": "01676877-8928-4094-b94e-ddbc80fe4be3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "age [58 44 33 47 35 28 42 43 41 29 53 57 51 45 60 56 32 25 40 39 52 46 36 49\n",
            " 59 37 50 54 55 48 24 38 31 30 27 34 23 26 61 22 21 20 66 62 83 75 67 70\n",
            " 65 68 64 69 72 71 19 76 85 63 90 82 73 74 78 80 94 79 77 86 95 81]\n",
            "job ['management' 'technician' 'entrepreneur' 'blue-collar' 'unknown'\n",
            " 'retired' 'admin' 'services' 'self-employed' 'unemployed' 'housemaid'\n",
            " 'student']\n",
            "marital ['married' 'single' 'divorced']\n",
            "education ['tertiary' 'secondary' 'unknown' 'primary']\n",
            "default ['no' 'yes']\n",
            "balance [  2143     29      2 ...   7222   3402 102127]\n",
            "housing ['yes' 'no']\n",
            "loan ['no' 'yes']\n",
            "contact ['unknown' 'cellular' 'telephone']\n",
            "day [ 5  6  7  8  9 12 13 14 15 16 19 20 21 23 26 27 28 29 30  2  3  4 11 17\n",
            " 18 24 25  1 10 22 31]\n",
            "month ['may' 'jun' 'jul' 'aug' 'oct' 'nov' 'dec' 'jan' 'feb' 'mar' 'apr']\n",
            "duration [ 261  151   76 ... 1880 1460 2219]\n",
            "campaign [ 1  2  3  5  4  6  7  8  9 10 11 12 13 19 14 24 16 32 18 22 15 17 25 21\n",
            " 43 51 63 41 26 28 55 50 38 23 20 29 31 37 30 46 27 58 33 35 34 36 39 44]\n",
            "y ['no' 'yes']\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39995</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39996</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39997</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39998</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39999</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>40000 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ],
            "text/plain": [
              "0        0\n",
              "1        0\n",
              "2        0\n",
              "3        0\n",
              "4        0\n",
              "        ..\n",
              "39995    0\n",
              "39996    1\n",
              "39997    1\n",
              "39998    0\n",
              "39999    0\n",
              "Name: y, Length: 40000, dtype: int64"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "for col in df.columns:\n",
        "  print(col, df[col].unique())\n",
        "  df_copy[col] = pd.factorize(df_copy[col])[0]\n",
        "# df_copy\n",
        "\n",
        "X2 = df_copy.drop(columns=['y'])   # The entire dataset is required so just drop Y.\n",
        "# X2\n",
        "y2 = df_copy['y']\n",
        "y2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sCUt0fPfhzd_"
      },
      "outputs": [],
      "source": [
        "# Split the dataset\n",
        "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.3, random_state=seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "ftLicC5vuJXm",
        "outputId": "ed56038c-1ebb-4b53-ca49-849748ee60be"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"X2_train2\",\n  \"rows\": 28000,\n  \"fields\": [\n    {\n      \"column\": \"contact\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1,\n          2,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"day\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8,\n        \"min\": 0,\n        \"max\": 30,\n        \"num_unique_values\": 31,\n        \"samples\": [\n          5,\n          14,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"month\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 0,\n        \"max\": 10,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          0,\n          2,\n          9\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"duration\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 272,\n        \"min\": 0,\n        \"max\": 1534,\n        \"num_unique_values\": 1429,\n        \"samples\": [\n          660,\n          948,\n          292\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"campaign\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 0,\n        \"max\": 47,\n        \"num_unique_values\": 45,\n        \"samples\": [\n          45,\n          15,\n          29\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "X2_train2"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-ff320136-cc4c-478f-8add-e51667336e9b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>contact</th>\n",
              "      <th>day</th>\n",
              "      <th>month</th>\n",
              "      <th>duration</th>\n",
              "      <th>campaign</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>14519</th>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>687</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33270</th>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32114</th>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>10</td>\n",
              "      <td>733</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33371</th>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>10</td>\n",
              "      <td>343</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25384</th>\n",
              "      <td>2</td>\n",
              "      <td>24</td>\n",
              "      <td>5</td>\n",
              "      <td>401</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12159</th>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>893</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38423</th>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>185</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13381</th>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>144</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26054</th>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>5</td>\n",
              "      <td>371</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18977</th>\n",
              "      <td>1</td>\n",
              "      <td>21</td>\n",
              "      <td>3</td>\n",
              "      <td>927</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>28000 rows × 5 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ff320136-cc4c-478f-8add-e51667336e9b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ff320136-cc4c-478f-8add-e51667336e9b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ff320136-cc4c-478f-8add-e51667336e9b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-56b3cb4c-c9e5-4189-b749-657ffe159c01\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-56b3cb4c-c9e5-4189-b749-657ffe159c01')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-56b3cb4c-c9e5-4189-b749-657ffe159c01 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_ef78a22f-74d7-401a-9aca-d8a61371b839\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('X2_train2')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_ef78a22f-74d7-401a-9aca-d8a61371b839 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('X2_train2');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "       contact  day  month  duration  campaign\n",
              "14519        1    8      2       687         2\n",
              "33270        1   11     10         3         2\n",
              "32114        1    8     10       733         2\n",
              "33371        1   11     10       343         4\n",
              "25384        2   24      5       401         2\n",
              "...        ...  ...    ...       ...       ...\n",
              "12159        0   11      1       893         1\n",
              "38423        1    8      0       185         7\n",
              "13381        2    4      2       144         0\n",
              "26054        1   10      5       371         2\n",
              "18977        1   21      3       927         1\n",
              "\n",
              "[28000 rows x 5 columns]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# X2_train is the entire dataset - should I apply the whole df for training\n",
        "X2_train2 = X2_train[['contact', 'day', 'month', 'duration', 'campaign']]   # these are the campaign related features.\n",
        "X2_train2\n",
        "\n",
        "# X2_train2 is the df that only extracts campaign related featuers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofnKRq4F0Urm"
      },
      "source": [
        "### Reusing the train_test_split from Layer 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2R0Gxd7SNTSE"
      },
      "outputs": [],
      "source": [
        "X = df_copy.drop(columns=['y'])  #Q1. I remove the call-related features, are these correct? The dtypes of each of them are objects and\n",
        "y2 = df_copy['y']\n",
        "\n",
        "# Identify categorical columns\n",
        "categorical_columns = X.select_dtypes(include=['object']).columns\n",
        "# print(categorical_columns)\n",
        "# print(X1)\n",
        "\n",
        "# Encode categorical features\n",
        "label_encoder = LabelEncoder()\n",
        "# print(label_encoder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "16Tm8RxNOnmI"
      },
      "outputs": [],
      "source": [
        "# Split the dataset\n",
        "X2_train, X2_test, y2_train, y2_test = train_test_split(X, y2, test_size=0.3, random_state=seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "5xMnsUirATyo",
        "outputId": "7a023f0c-c844-4e51-fa81-77bcd3a658a5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>29368</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9801</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4375</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38238</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24964</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4752</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29992</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12580</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33362</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16798</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>12000 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ],
            "text/plain": [
              "29368    0\n",
              "9801     0\n",
              "4375     0\n",
              "38238    0\n",
              "24964    0\n",
              "        ..\n",
              "4752     0\n",
              "29992    0\n",
              "12580    0\n",
              "33362    0\n",
              "16798    0\n",
              "Name: y, Length: 12000, dtype: int64"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# y2_train\n",
        "y2_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uvayslrA1d4O"
      },
      "outputs": [],
      "source": [
        "# X1_train_rus\n",
        "y2_train = y2_train.replace({'no':0, 'yes':1}, inplace=False)\n",
        "y2_test = y2_test.replace({'no':0, 'yes':1}, inplace=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBCrCTVKFCli"
      },
      "source": [
        "### 2nd Layer: to predict which of the customers we should keep calling to <br>\n",
        "Few tips to do: <br>\n",
        "- Utilize the entire dataset with the complete set of all features. (Start from scratch) <br>\n",
        "- Campaign related features: <br>\n",
        "predict which of the customers we should keep calling, assuming initial round of calls have already made been -> campaign related features <br>\n",
        "\n",
        "Similar to the previous steps: start with experimenting few different models.\n",
        "Maybe try RandomUnderSampler, because it worked well and then experiment with few different models. <br>\n",
        "\n",
        "This time, the goal is different, predicting which of the customer we should keep calling. Precision for class 1. (which of them precised correctly)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6R8j4TLNUcHZ"
      },
      "source": [
        "#### Data - RandomUnderSampler\n",
        "\n",
        "\n",
        "|Data|Model||\n",
        "|------|---|---|\n",
        "|RUS (RandomUnderSampler)|RandomForestClassifier|\n",
        "| |XGBClassifier|\n",
        "| |SGDClassifier|\n",
        "| |SVC|\n",
        "| |LGBMClassifier|\n",
        "| |DecisionTreeClassifier|\n",
        "| |Perceptron|\n",
        "\n",
        "\n",
        "\n",
        "Techniques used in here:\n",
        "1. RandomForestClassifier / XGBClassifier / SGDClassifier / SVC / LGBMClassifier/ DecisionTreeClassifier / Perceptron\n",
        "2. SMOTE\n",
        "3. SMOTE-Tomek\n",
        "4. SMOTEEN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vzmbdAfRHMm6"
      },
      "source": [
        "#### Efficient Code for RandUnderSampler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "azK_cM-AEiPS",
        "outputId": "7a97c9ac-ab2a-4c81-800e-d115501254f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RandomUnderSampler - Class Distribution After Resampling:\n",
            "y\n",
            "0    2020\n",
            "1    2020\n",
            "Name: count, dtype: int64\n",
            "\n",
            "RandomUnderSampler with RandomForestClassifier - Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.83      0.90     11124\n",
            "           1       0.27      0.81      0.40       876\n",
            "\n",
            "    accuracy                           0.83     12000\n",
            "   macro avg       0.63      0.82      0.65     12000\n",
            "weighted avg       0.93      0.83      0.86     12000\n",
            "\n",
            "RandomUnderSampler with RandomForestClassifier - F0.5 Score: 0.3111777150916784\n",
            "RandomUnderSampler with RandomForestClassifier - F2 Score: 0.5767031530795622\n",
            "\n",
            "RandomUnderSampler - Class Distribution After Resampling:\n",
            "y\n",
            "0    2020\n",
            "1    2020\n",
            "Name: count, dtype: int64\n",
            "\n",
            "RandomUnderSampler with XGBClassifier - Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.82      0.89     11124\n",
            "           1       0.26      0.79      0.39       876\n",
            "\n",
            "    accuracy                           0.82     12000\n",
            "   macro avg       0.62      0.80      0.64     12000\n",
            "weighted avg       0.93      0.82      0.86     12000\n",
            "\n",
            "RandomUnderSampler with XGBClassifier - F0.5 Score: 0.2948234487487144\n",
            "RandomUnderSampler with XGBClassifier - F2 Score: 0.5546597871654305\n",
            "\n",
            "RandomUnderSampler - Class Distribution After Resampling:\n",
            "y\n",
            "0    2020\n",
            "1    2020\n",
            "Name: count, dtype: int64\n",
            "\n",
            "RandomUnderSampler with SGDClassifier - Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.79      0.86     11124\n",
            "           1       0.14      0.44      0.21       876\n",
            "\n",
            "    accuracy                           0.76     12000\n",
            "   macro avg       0.54      0.61      0.54     12000\n",
            "weighted avg       0.89      0.76      0.81     12000\n",
            "\n",
            "RandomUnderSampler with SGDClassifier - F0.5 Score: 0.16208418194161575\n",
            "RandomUnderSampler with SGDClassifier - F2 Score: 0.3065318568448082\n",
            "\n",
            "RandomUnderSampler - Class Distribution After Resampling:\n",
            "y\n",
            "0    2020\n",
            "1    2020\n",
            "Name: count, dtype: int64\n",
            "\n",
            "RandomUnderSampler with SVC - Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.86      0.91     11124\n",
            "           1       0.25      0.62      0.36       876\n",
            "\n",
            "    accuracy                           0.84     12000\n",
            "   macro avg       0.61      0.74      0.63     12000\n",
            "weighted avg       0.91      0.84      0.87     12000\n",
            "\n",
            "RandomUnderSampler with SVC - F0.5 Score: 0.288135593220339\n",
            "RandomUnderSampler with SVC - F2 Score: 0.4818423383525244\n",
            "\n",
            "RandomUnderSampler - Class Distribution After Resampling:\n",
            "y\n",
            "0    2020\n",
            "1    2020\n",
            "Name: count, dtype: int64\n",
            "\n",
            "[LightGBM] [Info] Number of positive: 2020, number of negative: 2020\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011288 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 657\n",
            "[LightGBM] [Info] Number of data points in the train set: 4040, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "RandomUnderSampler with LGBMClassifier - Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.83      0.90     11124\n",
            "           1       0.27      0.80      0.41       876\n",
            "\n",
            "    accuracy                           0.83     12000\n",
            "   macro avg       0.63      0.82      0.65     12000\n",
            "weighted avg       0.93      0.83      0.87     12000\n",
            "\n",
            "RandomUnderSampler with LGBMClassifier - F0.5 Score: 0.31587959625090123\n",
            "RandomUnderSampler with LGBMClassifier - F2 Score: 0.5784782967486384\n",
            "\n",
            "RandomUnderSampler - Class Distribution After Resampling:\n",
            "y\n",
            "0    2020\n",
            "1    2020\n",
            "Name: count, dtype: int64\n",
            "\n",
            "RandomUnderSampler with DecisionTreeClassifier - Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.72      0.83     11124\n",
            "           1       0.17      0.71      0.27       876\n",
            "\n",
            "    accuracy                           0.72     12000\n",
            "   macro avg       0.57      0.72      0.55     12000\n",
            "weighted avg       0.91      0.72      0.79     12000\n",
            "\n",
            "RandomUnderSampler with DecisionTreeClassifier - F0.5 Score: 0.19787152689268417\n",
            "RandomUnderSampler with DecisionTreeClassifier - F2 Score: 0.4307713651498335\n",
            "\n",
            "RandomUnderSampler - Class Distribution After Resampling:\n",
            "y\n",
            "0    2020\n",
            "1    2020\n",
            "Name: count, dtype: int64\n",
            "\n",
            "RandomUnderSampler with Perceptron - Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.30      0.46     11124\n",
            "           1       0.09      0.87      0.16       876\n",
            "\n",
            "    accuracy                           0.34     12000\n",
            "   macro avg       0.53      0.58      0.31     12000\n",
            "weighted avg       0.90      0.34      0.44     12000\n",
            "\n",
            "RandomUnderSampler with Perceptron - F0.5 Score: 0.10857142857142857\n",
            "RandomUnderSampler with Perceptron - F2 Score: 0.31574574158703783\n",
            "\n",
            "SMOTE - Class Distribution After Resampling:\n",
            "y\n",
            "1    25980\n",
            "0    25980\n",
            "Name: count, dtype: int64\n",
            "\n",
            "SMOTE with RandomForestClassifier - Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.94      0.94     11124\n",
            "           1       0.34      0.43      0.38       876\n",
            "\n",
            "    accuracy                           0.90     12000\n",
            "   macro avg       0.65      0.68      0.66     12000\n",
            "weighted avg       0.91      0.90      0.90     12000\n",
            "\n",
            "SMOTE with RandomForestClassifier - F0.5 Score: 0.35795454545454547\n",
            "SMOTE with RandomForestClassifier - F2 Score: 0.41042345276872966\n",
            "\n",
            "SMOTE - Class Distribution After Resampling:\n",
            "y\n",
            "1    25980\n",
            "0    25980\n",
            "Name: count, dtype: int64\n",
            "\n",
            "SMOTE with XGBClassifier - Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.93      0.94     11124\n",
            "           1       0.35      0.48      0.41       876\n",
            "\n",
            "    accuracy                           0.90     12000\n",
            "   macro avg       0.66      0.71      0.68     12000\n",
            "weighted avg       0.91      0.90      0.90     12000\n",
            "\n",
            "SMOTE with XGBClassifier - F0.5 Score: 0.3736749116607774\n",
            "SMOTE with XGBClassifier - F2 Score: 0.45\n",
            "\n",
            "SMOTE - Class Distribution After Resampling:\n",
            "y\n",
            "1    25980\n",
            "0    25980\n",
            "Name: count, dtype: int64\n",
            "\n",
            "SMOTE with SGDClassifier - Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.65      0.78     11124\n",
            "           1       0.15      0.81      0.26       876\n",
            "\n",
            "    accuracy                           0.66     12000\n",
            "   macro avg       0.57      0.73      0.52     12000\n",
            "weighted avg       0.92      0.66      0.74     12000\n",
            "\n",
            "SMOTE with SGDClassifier - F0.5 Score: 0.1827080770807708\n",
            "SMOTE with SGDClassifier - F2 Score: 0.43672669361754257\n",
            "\n",
            "SMOTE - Class Distribution After Resampling:\n",
            "y\n",
            "1    25980\n",
            "0    25980\n",
            "Name: count, dtype: int64\n",
            "\n",
            "SMOTE with SVC - Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.88      0.92     11124\n",
            "           1       0.27      0.58      0.37       876\n",
            "\n",
            "    accuracy                           0.86     12000\n",
            "   macro avg       0.62      0.73      0.64     12000\n",
            "weighted avg       0.91      0.86      0.88     12000\n",
            "\n",
            "SMOTE with SVC - F0.5 Score: 0.30371605526441164\n",
            "SMOTE with SVC - F2 Score: 0.4736255572065379\n",
            "\n",
            "SMOTE - Class Distribution After Resampling:\n",
            "y\n",
            "1    25980\n",
            "0    25980\n",
            "Name: count, dtype: int64\n",
            "\n",
            "[LightGBM] [Info] Number of positive: 25980, number of negative: 25980\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005327 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 687\n",
            "[LightGBM] [Info] Number of data points in the train set: 51960, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "SMOTE with LGBMClassifier - Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.91      0.93     11124\n",
            "           1       0.32      0.55      0.40       876\n",
            "\n",
            "    accuracy                           0.88     12000\n",
            "   macro avg       0.64      0.73      0.67     12000\n",
            "weighted avg       0.92      0.88      0.89     12000\n",
            "\n",
            "SMOTE with LGBMClassifier - F0.5 Score: 0.3460207612456747\n",
            "SMOTE with LGBMClassifier - F2 Score: 0.4781829049611476\n",
            "\n",
            "SMOTE - Class Distribution After Resampling:\n",
            "y\n",
            "1    25980\n",
            "0    25980\n",
            "Name: count, dtype: int64\n",
            "\n",
            "SMOTE with DecisionTreeClassifier - Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.88      0.91     11124\n",
            "           1       0.21      0.41      0.28       876\n",
            "\n",
            "    accuracy                           0.85     12000\n",
            "   macro avg       0.58      0.64      0.60     12000\n",
            "weighted avg       0.90      0.85      0.87     12000\n",
            "\n",
            "SMOTE with DecisionTreeClassifier - F0.5 Score: 0.23516163222045575\n",
            "SMOTE with DecisionTreeClassifier - F2 Score: 0.3431941221964424\n",
            "\n",
            "SMOTE - Class Distribution After Resampling:\n",
            "y\n",
            "1    25980\n",
            "0    25980\n",
            "Name: count, dtype: int64\n",
            "\n",
            "SMOTE with Perceptron - Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.27      0.42     11124\n",
            "           1       0.09      0.92      0.16       876\n",
            "\n",
            "    accuracy                           0.32     12000\n",
            "   macro avg       0.53      0.59      0.29     12000\n",
            "weighted avg       0.91      0.32      0.40     12000\n",
            "\n",
            "SMOTE with Perceptron - F0.5 Score: 0.11003280481137233\n",
            "SMOTE with Perceptron - F2 Score: 0.3238133547868061\n",
            "\n",
            "SMOTE-Tomek - Class Distribution After Resampling:\n",
            "y\n",
            "1    25369\n",
            "0    25369\n",
            "Name: count, dtype: int64\n",
            "\n",
            "SMOTE-Tomek with RandomForestClassifier - Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.93      0.94     11124\n",
            "           1       0.35      0.44      0.39       876\n",
            "\n",
            "    accuracy                           0.90     12000\n",
            "   macro avg       0.65      0.69      0.67     12000\n",
            "weighted avg       0.91      0.90      0.90     12000\n",
            "\n",
            "SMOTE-Tomek with RandomForestClassifier - F0.5 Score: 0.36140089418777943\n",
            "SMOTE-Tomek with RandomForestClassifier - F2 Score: 0.4192781499891939\n",
            "\n",
            "SMOTE-Tomek - Class Distribution After Resampling:\n",
            "y\n",
            "1    25369\n",
            "0    25369\n",
            "Name: count, dtype: int64\n",
            "\n",
            "SMOTE-Tomek with XGBClassifier - Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.93      0.94     11124\n",
            "           1       0.35      0.48      0.41       876\n",
            "\n",
            "    accuracy                           0.90     12000\n",
            "   macro avg       0.66      0.70      0.68     12000\n",
            "weighted avg       0.91      0.90      0.91     12000\n",
            "\n",
            "SMOTE-Tomek with XGBClassifier - F0.5 Score: 0.37392395982783355\n",
            "SMOTE-Tomek with XGBClassifier - F2 Score: 0.44560803590510795\n",
            "\n",
            "SMOTE-Tomek - Class Distribution After Resampling:\n",
            "y\n",
            "1    25369\n",
            "0    25369\n",
            "Name: count, dtype: int64\n",
            "\n",
            "SMOTE-Tomek with SGDClassifier - Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.90      0.93     11124\n",
            "           1       0.29      0.50      0.36       876\n",
            "\n",
            "    accuracy                           0.87     12000\n",
            "   macro avg       0.62      0.70      0.65     12000\n",
            "weighted avg       0.91      0.87      0.89     12000\n",
            "\n",
            "SMOTE-Tomek with SGDClassifier - F0.5 Score: 0.31214121699196323\n",
            "SMOTE-Tomek with SGDClassifier - F2 Score: 0.4326636164710563\n",
            "\n",
            "SMOTE-Tomek - Class Distribution After Resampling:\n",
            "y\n",
            "1    25369\n",
            "0    25369\n",
            "Name: count, dtype: int64\n",
            "\n",
            "SMOTE-Tomek with SVC - Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.88      0.92     11124\n",
            "           1       0.27      0.58      0.37       876\n",
            "\n",
            "    accuracy                           0.86     12000\n",
            "   macro avg       0.62      0.73      0.64     12000\n",
            "weighted avg       0.91      0.86      0.88     12000\n",
            "\n",
            "SMOTE-Tomek with SVC - F0.5 Score: 0.30416666666666664\n",
            "SMOTE-Tomek with SVC - F2 Score: 0.4744661095636026\n",
            "\n",
            "SMOTE-Tomek - Class Distribution After Resampling:\n",
            "y\n",
            "1    25369\n",
            "0    25369\n",
            "Name: count, dtype: int64\n",
            "\n",
            "[LightGBM] [Info] Number of positive: 25369, number of negative: 25369\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006409 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 687\n",
            "[LightGBM] [Info] Number of data points in the train set: 50738, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "SMOTE-Tomek with LGBMClassifier - Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.91      0.93     11124\n",
            "           1       0.32      0.55      0.40       876\n",
            "\n",
            "    accuracy                           0.88     12000\n",
            "   macro avg       0.64      0.73      0.67     12000\n",
            "weighted avg       0.92      0.88      0.90     12000\n",
            "\n",
            "SMOTE-Tomek with LGBMClassifier - F0.5 Score: 0.3484673221515327\n",
            "SMOTE-Tomek with LGBMClassifier - F2 Score: 0.4806541683286797\n",
            "\n",
            "SMOTE-Tomek - Class Distribution After Resampling:\n",
            "y\n",
            "1    25369\n",
            "0    25369\n",
            "Name: count, dtype: int64\n",
            "\n",
            "SMOTE-Tomek with DecisionTreeClassifier - Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.88      0.92     11124\n",
            "           1       0.22      0.44      0.30       876\n",
            "\n",
            "    accuracy                           0.85     12000\n",
            "   macro avg       0.59      0.66      0.61     12000\n",
            "weighted avg       0.90      0.85      0.87     12000\n",
            "\n",
            "SMOTE-Tomek with DecisionTreeClassifier - F0.5 Score: 0.24779449922158797\n",
            "SMOTE-Tomek with DecisionTreeClassifier - F2 Score: 0.3664620107444359\n",
            "\n",
            "SMOTE-Tomek - Class Distribution After Resampling:\n",
            "y\n",
            "1    25369\n",
            "0    25369\n",
            "Name: count, dtype: int64\n",
            "\n",
            "SMOTE-Tomek with Perceptron - Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.23      0.37     11124\n",
            "           1       0.09      0.93      0.16       876\n",
            "\n",
            "    accuracy                           0.28     12000\n",
            "   macro avg       0.53      0.58      0.27     12000\n",
            "weighted avg       0.91      0.28      0.36     12000\n",
            "\n",
            "SMOTE-Tomek with Perceptron - F0.5 Score: 0.10594543940024989\n",
            "SMOTE-Tomek with Perceptron - F2 Score: 0.3157731398867251\n",
            "\n",
            "SMOTE-ENN - Class Distribution After Resampling:\n",
            "y\n",
            "1    22497\n",
            "0    17384\n",
            "Name: count, dtype: int64\n",
            "\n",
            "SMOTE-ENN with RandomForestClassifier - Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.89      0.93     11124\n",
            "           1       0.31      0.64      0.42       876\n",
            "\n",
            "    accuracy                           0.87     12000\n",
            "   macro avg       0.64      0.76      0.67     12000\n",
            "weighted avg       0.92      0.87      0.89     12000\n",
            "\n",
            "SMOTE-ENN with RandomForestClassifier - F0.5 Score: 0.34516765285996054\n",
            "SMOTE-ENN with RandomForestClassifier - F2 Score: 0.5270092226613966\n",
            "\n",
            "SMOTE-ENN - Class Distribution After Resampling:\n",
            "y\n",
            "1    22497\n",
            "0    17384\n",
            "Name: count, dtype: int64\n",
            "\n",
            "SMOTE-ENN with XGBClassifier - Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.89      0.93     11124\n",
            "           1       0.31      0.63      0.41       876\n",
            "\n",
            "    accuracy                           0.87     12000\n",
            "   macro avg       0.64      0.76      0.67     12000\n",
            "weighted avg       0.92      0.87      0.89     12000\n",
            "\n",
            "SMOTE-ENN with XGBClassifier - F0.5 Score: 0.3416912487708948\n",
            "SMOTE-ENN with XGBClassifier - F2 Score: 0.5226546343297612\n",
            "\n",
            "SMOTE-ENN - Class Distribution After Resampling:\n",
            "y\n",
            "1    22497\n",
            "0    17384\n",
            "Name: count, dtype: int64\n",
            "\n",
            "SMOTE-ENN with SGDClassifier - Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.86      0.90     11124\n",
            "           1       0.19      0.42      0.26       876\n",
            "\n",
            "    accuracy                           0.83     12000\n",
            "   macro avg       0.57      0.64      0.58     12000\n",
            "weighted avg       0.89      0.83      0.85     12000\n",
            "\n",
            "SMOTE-ENN with SGDClassifier - F0.5 Score: 0.21390682656826568\n",
            "SMOTE-ENN with SGDClassifier - F2 Score: 0.34017971758664955\n",
            "\n",
            "SMOTE-ENN - Class Distribution After Resampling:\n",
            "y\n",
            "1    22497\n",
            "0    17384\n",
            "Name: count, dtype: int64\n",
            "\n",
            "SMOTE-ENN with SVC - Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.83      0.89     11124\n",
            "           1       0.23      0.64      0.33       876\n",
            "\n",
            "    accuracy                           0.81     12000\n",
            "   macro avg       0.60      0.73      0.61     12000\n",
            "weighted avg       0.91      0.81      0.85     12000\n",
            "\n",
            "SMOTE-ENN with SVC - F0.5 Score: 0.2585406609728927\n",
            "SMOTE-ENN with SVC - F2 Score: 0.46587487453997994\n",
            "\n",
            "SMOTE-ENN - Class Distribution After Resampling:\n",
            "y\n",
            "1    22497\n",
            "0    17384\n",
            "Name: count, dtype: int64\n",
            "\n",
            "[LightGBM] [Info] Number of positive: 22497, number of negative: 17384\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003782 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 684\n",
            "[LightGBM] [Info] Number of data points in the train set: 39881, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.564103 -> initscore=0.257832\n",
            "[LightGBM] [Info] Start training from score 0.257832\n",
            "SMOTE-ENN with LGBMClassifier - Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.87      0.92     11124\n",
            "           1       0.29      0.68      0.41       876\n",
            "\n",
            "    accuracy                           0.86     12000\n",
            "   macro avg       0.63      0.78      0.66     12000\n",
            "weighted avg       0.92      0.86      0.88     12000\n",
            "\n",
            "SMOTE-ENN with LGBMClassifier - F0.5 Score: 0.32981530343007914\n",
            "SMOTE-ENN with LGBMClassifier - F2 Score: 0.5396654074473827\n",
            "\n",
            "SMOTE-ENN - Class Distribution After Resampling:\n",
            "y\n",
            "1    22497\n",
            "0    17384\n",
            "Name: count, dtype: int64\n",
            "\n",
            "SMOTE-ENN with DecisionTreeClassifier - Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.85      0.90     11124\n",
            "           1       0.23      0.60      0.34       876\n",
            "\n",
            "    accuracy                           0.83     12000\n",
            "   macro avg       0.60      0.72      0.62     12000\n",
            "weighted avg       0.91      0.83      0.86     12000\n",
            "\n",
            "SMOTE-ENN with DecisionTreeClassifier - F0.5 Score: 0.26629327902240324\n",
            "SMOTE-ENN with DecisionTreeClassifier - F2 Score: 0.45557491289198604\n",
            "\n",
            "SMOTE-ENN - Class Distribution After Resampling:\n",
            "y\n",
            "1    22497\n",
            "0    17384\n",
            "Name: count, dtype: int64\n",
            "\n",
            "SMOTE-ENN with Perceptron - Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.91      0.93     11124\n",
            "           1       0.22      0.32      0.26       876\n",
            "\n",
            "    accuracy                           0.87     12000\n",
            "   macro avg       0.58      0.61      0.59     12000\n",
            "weighted avg       0.89      0.87      0.88     12000\n",
            "\n",
            "SMOTE-ENN with Perceptron - F0.5 Score: 0.23043766578249336\n",
            "SMOTE-ENN with Perceptron - F2 Score: 0.29000625912789485\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Define a function to train and evaluate different models with different samplers\n",
        "def train_and_evaluate_ru_models(X_train, y_train, X_test, y_test, sampler, sampler_name, classifier, classifier_name):\n",
        "    # Resample the training data\n",
        "    X_resampled, y_resampled = sampler.fit_resample(X_train, y_train)\n",
        "    print(f\"{sampler_name} - Class Distribution After Resampling:\\n{y_resampled.value_counts()}\\n\")\n",
        "\n",
        "    # Train the model\n",
        "    model = classifier\n",
        "    model.fit(X_resampled, y_resampled)\n",
        "\n",
        "    # Predict on the test set\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Print evaluation metrics\n",
        "    print(f\"{sampler_name} with {classifier_name} - Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "    fhalf_score = fbeta_score(y_test, y_pred, beta=0.5)\n",
        "    f2_score = fbeta_score(y_test, y_pred, beta=2)\n",
        "    print(f\"{sampler_name} with {classifier_name} - F0.5 Score: {fhalf_score}\")\n",
        "    print(f\"{sampler_name} with {classifier_name} - F2 Score: {f2_score}\\n\")\n",
        "\n",
        "# List of classifiers to test\n",
        "classifiers = [\n",
        "    (RandomForestClassifier(random_state=seed), \"RandomForestClassifier\"),\n",
        "    (XGBClassifier(random_state=seed, use_label_encoder=False, eval_metric='mlogloss'), \"XGBClassifier\"),\n",
        "    (SGDClassifier(random_state=seed), \"SGDClassifier\"),\n",
        "    (SVC(random_state=seed), \"SVC\"),\n",
        "    (LGBMClassifier(random_state=seed), \"LGBMClassifier\"),\n",
        "    (DecisionTreeClassifier(random_state=seed), \"DecisionTreeClassifier\"),\n",
        "    (Perceptron(random_state=seed), \"Perceptron\")\n",
        "]\n",
        "\n",
        "# List of resampling techniques to apply\n",
        "samplers = [\n",
        "    (RandomUnderSampler(sampling_strategy='majority', random_state=seed), \"RandomUnderSampler\"),\n",
        "    (SMOTE(sampling_strategy='minority', random_state=seed), \"SMOTE\"),\n",
        "    (SMOTETomek(sampling_strategy='minority', random_state=seed), \"SMOTE-Tomek\"),\n",
        "    (SMOTEENN(sampling_strategy='minority', random_state=seed), \"SMOTE-ENN\")\n",
        "]\n",
        "\n",
        "# Run the training and evaluation for each combination of sampler and classifier\n",
        "for sampler, sampler_name in samplers:\n",
        "    for classifier, classifier_name in classifiers:\n",
        "        train_and_evaluate_ru_models(X2_train, y2_train, X2_test, y2_test, sampler, sampler_name, classifier, classifier_name)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZNvYR3sfVeA"
      },
      "source": [
        "##### RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fCLcy9nXfV2o",
        "outputId": "fe77c3f9-de8c-4294-f555-b1c9030598a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "y\n",
            "0    2020\n",
            "1    2020\n",
            "Name: count, dtype: int64\n",
            "RandomForestClassifier Applied with RandomUnderSampler: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.83      0.90     11124\n",
            "           1       0.27      0.81      0.40       876\n",
            "\n",
            "    accuracy                           0.83     12000\n",
            "   macro avg       0.63      0.82      0.65     12000\n",
            "weighted avg       0.93      0.83      0.86     12000\n",
            "\n",
            "F0.5 Score: 0.3111777150916784\n",
            "F2 Score: 0.5767031530795622\n",
            "y\n",
            "1    25980\n",
            "0    25980\n",
            "Name: count, dtype: int64\n",
            "RFC-SMOTE Applied: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.94      0.94     11124\n",
            "           1       0.34      0.43      0.38       876\n",
            "\n",
            "    accuracy                           0.90     12000\n",
            "   macro avg       0.65      0.68      0.66     12000\n",
            "weighted avg       0.91      0.90      0.90     12000\n",
            "\n",
            "F0.5 Score: 0.35795454545454547\n",
            "F2 Score: 0.41042345276872966\n",
            "y\n",
            "1    25369\n",
            "0    25369\n",
            "Name: count, dtype: int64\n",
            "RFC-SMOTE TOMEK Applied: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.93      0.94     11124\n",
            "           1       0.35      0.44      0.39       876\n",
            "\n",
            "    accuracy                           0.90     12000\n",
            "   macro avg       0.65      0.69      0.67     12000\n",
            "weighted avg       0.91      0.90      0.90     12000\n",
            "\n",
            "F0.5 Score: 0.36140089418777943\n",
            "F2 Score: 0.4192781499891939\n",
            "y\n",
            "1    22497\n",
            "0    17384\n",
            "Name: count, dtype: int64\n",
            "RFC-SMOTEEN Applied: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.89      0.93     11124\n",
            "           1       0.31      0.64      0.42       876\n",
            "\n",
            "    accuracy                           0.87     12000\n",
            "   macro avg       0.64      0.76      0.67     12000\n",
            "weighted avg       0.92      0.87      0.89     12000\n",
            "\n",
            "F0.5 Score: 0.34516765285996054\n",
            "F2 Score: 0.5270092226613966\n"
          ]
        }
      ],
      "source": [
        "# 1. Apply RandomUnderSampler\n",
        "rus = RandomUnderSampler(sampling_strategy='majority', random_state=seed)\n",
        "X2_train_rus, y2_train_rus = rus.fit_resample(X2_train, y2_train)  # instead of using the entire dataset, apply o\n",
        "print(y2_train_rus.value_counts())\n",
        "\n",
        "# Initiate RandomForestClassifier\n",
        "rfc_rus = RandomForestClassifier(random_state=seed)\n",
        "rfc_rus.fit(X2_train_rus, y2_train_rus)\n",
        "y2_pred = rfc_rus.predict(X2_test)\n",
        "print(f\"RandomForestClassifier Applied with RandomUnderSampler: \\n\", classification_report(y2_test, y2_pred))\n",
        "# the result is skewed, since the data is imbalanced\n",
        "fhalf_score = fbeta_score(y2_test, y2_pred, beta=0.5)\n",
        "print(f\"F0.5 Score: {fhalf_score}\")\n",
        "f2_score = fbeta_score(y2_test, y2_pred, beta=2)\n",
        "print(f\"F2 Score: {f2_score}\")\n",
        "\n",
        "# 2. Apply SMOTE (Synthetic Minotiry Oversampling Technique)\n",
        "sm = SMOTE(sampling_strategy = 'minority', random_state=seed)\n",
        "X2_train_sm, y2_train_sm = sm.fit_resample(X2_train, y2_train)\n",
        "print(y2_train_sm.value_counts())\n",
        "# Initiating RandomForestClassifier\n",
        "rfc_sm = RandomForestClassifier(random_state=seed)\n",
        "rfc_sm.fit(X2_train_sm, y2_train_sm)\n",
        "y2_pred_sm = rfc_sm.predict(X2_test)\n",
        "print(f\"RFC-SMOTE Applied: \\n\", classification_report(y2_test, y2_pred_sm))\n",
        "fhalf_score_sm = fbeta_score(y2_test, y2_pred_sm, beta=0.5)\n",
        "print(f\"F0.5 Score: {fhalf_score_sm}\")\n",
        "f2_score_sm = fbeta_score(y2_test, y2_pred_sm, beta=2)\n",
        "print(f\"F2 Score: {f2_score_sm}\")\n",
        "\n",
        "# 3. Apply SMOTE-TOMEK\n",
        "smt = SMOTETomek(sampling_strategy = 'minority', random_state=seed)\n",
        "X2_train_smt, y2_train_smt = smt.fit_resample(X2_train, y2_train)\n",
        "print(y2_train_smt.value_counts())\n",
        "# Initiating RandomForestClassifier\n",
        "rfc_smt = RandomForestClassifier(random_state=seed)\n",
        "rfc_smt.fit(X2_train_smt, y2_train_smt)\n",
        "y2_pred_smt = rfc_smt.predict(X2_test)\n",
        "print(f\"RFC-SMOTE TOMEK Applied: \\n\", classification_report(y2_test, y2_pred_smt))\n",
        "fhalf_score_smt = fbeta_score(y2_test, y2_pred_smt, beta=0.5)\n",
        "print(f\"F0.5 Score: {fhalf_score_smt}\")\n",
        "f2_score_smt = fbeta_score(y2_test, y2_pred_smt, beta=2)\n",
        "print(f\"F2 Score: {f2_score_smt}\")\n",
        "\n",
        "# 4. Apply SMOTEEN to balance the classes\n",
        "smn = SMOTEENN(sampling_strategy = 'minority', random_state=seed)\n",
        "X2_train_smn, y2_train_smn = smn.fit_resample(X2_train, y2_train)\n",
        "print(y2_train_smn.value_counts())\n",
        "# Initiating RandomForestClassifier\n",
        "rfc_smn = RandomForestClassifier(random_state=seed)\n",
        "rfc_smn.fit(X2_train_smn, y2_train_smn)\n",
        "y2_pred_smn = rfc_smn.predict(X2_test)\n",
        "print(f\"RFC-SMOTEEN Applied: \\n\", classification_report(y2_test, y2_pred_smn))\n",
        "fhalf_score_smn = fbeta_score(y2_test, y2_pred_smn, beta=0.5)\n",
        "print(f\"F0.5 Score: {fhalf_score_smn}\")\n",
        "f2_score_smn = fbeta_score(y2_test, y2_pred_smn, beta=2)\n",
        "print(f\"F2 Score: {f2_score_smn}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6LDHQzHfLv0"
      },
      "source": [
        "##### XGBClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lAgAY8FrPv7T",
        "outputId": "afeff097-7f64-48e5-ef54-a4030f911d57"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "y\n",
            "0    2020\n",
            "1    2020\n",
            "Name: count, dtype: int64\n",
            "XGBClassifier Applied with RandomUnderSampler: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.82      0.89     11124\n",
            "           1       0.26      0.79      0.39       876\n",
            "\n",
            "    accuracy                           0.82     12000\n",
            "   macro avg       0.62      0.80      0.64     12000\n",
            "weighted avg       0.93      0.82      0.86     12000\n",
            "\n",
            "F0.5 Score: 0.2948234487487144\n",
            "F2 Score: 0.5546597871654305\n",
            "y\n",
            "1    25980\n",
            "0    25980\n",
            "Name: count, dtype: int64\n",
            "XGB-SMOTE Applied: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.93      0.94     11124\n",
            "           1       0.35      0.48      0.41       876\n",
            "\n",
            "    accuracy                           0.90     12000\n",
            "   macro avg       0.66      0.71      0.68     12000\n",
            "weighted avg       0.91      0.90      0.90     12000\n",
            "\n",
            "F0.5 Score: 0.3736749116607774\n",
            "F2 Score: 0.45\n",
            "y\n",
            "1    25369\n",
            "0    25369\n",
            "Name: count, dtype: int64\n",
            "XGB-SMOTE TOMEK Applied: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.93      0.94     11124\n",
            "           1       0.35      0.48      0.41       876\n",
            "\n",
            "    accuracy                           0.90     12000\n",
            "   macro avg       0.66      0.70      0.68     12000\n",
            "weighted avg       0.91      0.90      0.91     12000\n",
            "\n",
            "F0.5 Score: 0.37392395982783355\n",
            "F2 Score: 0.44560803590510795\n",
            "y\n",
            "1    22497\n",
            "0    17384\n",
            "Name: count, dtype: int64\n",
            "XGB-SMOTEEN Applied: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.89      0.93     11124\n",
            "           1       0.31      0.63      0.41       876\n",
            "\n",
            "    accuracy                           0.87     12000\n",
            "   macro avg       0.64      0.76      0.67     12000\n",
            "weighted avg       0.92      0.87      0.89     12000\n",
            "\n",
            "F0.5 Score: 0.3416912487708948\n",
            "F2 Score: 0.5226546343297612\n"
          ]
        }
      ],
      "source": [
        "# 1. Apply RandomUnderSampler\n",
        "rus = RandomUnderSampler(sampling_strategy='majority', random_state=seed)\n",
        "X1_train_rus, y1_train_rus = rus.fit_resample(X2_train, y2_train)\n",
        "print(y2_train_rus.value_counts())\n",
        "\n",
        "# Initiate XGBClassifier\n",
        "xgb_rus = XGBClassifier(random_state=seed)\n",
        "xgb_rus.fit(X2_train_rus, y2_train_rus)\n",
        "y2_pred = xgb_rus.predict(X2_test)\n",
        "print(f\"XGBClassifier Applied with RandomUnderSampler: \\n\", classification_report(y2_test, y2_pred))\n",
        "# the result is skewed, since the data is imbalanced\n",
        "fhalf_score = fbeta_score(y2_test, y2_pred, beta=0.5)\n",
        "print(f\"F0.5 Score: {fhalf_score}\")\n",
        "f2_score = fbeta_score(y2_test, y2_pred, beta=2)\n",
        "print(f\"F2 Score: {f2_score}\")\n",
        "\n",
        "# 2. Apply SMOTE (Synthetic Minotiry Oversampling Technique)\n",
        "sm = SMOTE(sampling_strategy = 'minority', random_state=seed)\n",
        "X2_train_sm, y2_train_sm = sm.fit_resample(X2_train, y2_train)\n",
        "print(y2_train_sm.value_counts())\n",
        "# Initiating XGBClassifier\n",
        "xgb_sm = XGBClassifier(random_state=seed)\n",
        "xgb_sm.fit(X2_train_sm, y2_train_sm)\n",
        "y2_pred_sm = xgb_sm.predict(X2_test)\n",
        "print(f\"XGB-SMOTE Applied: \\n\", classification_report(y2_test, y2_pred_sm))\n",
        "fhalf_score_sm = fbeta_score(y2_test, y2_pred_sm, beta=0.5)\n",
        "print(f\"F0.5 Score: {fhalf_score_sm}\")\n",
        "f2_score_sm = fbeta_score(y2_test, y2_pred_sm, beta=2)\n",
        "print(f\"F2 Score: {f2_score_sm}\")\n",
        "\n",
        "# 3. Apply SMOTE-TOMEK\n",
        "smt = SMOTETomek(sampling_strategy = 'minority', random_state=seed)\n",
        "X2_train_smt, y1_train_smt = smt.fit_resample(X2_train, y2_train)\n",
        "print(y2_train_smt.value_counts())\n",
        "# Initiating XGBClassifier\n",
        "xgb_smt = XGBClassifier(random_state=seed)\n",
        "xgb_smt.fit(X2_train_smt, y2_train_smt)\n",
        "y2_pred_smt = xgb_smt.predict(X2_test)\n",
        "print(f\"XGB-SMOTE TOMEK Applied: \\n\", classification_report(y2_test, y2_pred_smt))\n",
        "fhalf_score_smt = fbeta_score(y2_test, y2_pred_smt, beta=0.5)\n",
        "print(f\"F0.5 Score: {fhalf_score_smt}\")\n",
        "f2_score_smt = fbeta_score(y2_test, y2_pred_smt, beta=2)\n",
        "print(f\"F2 Score: {f2_score_smt}\")\n",
        "\n",
        "# 4. Apply SMOTEEN to balance the classes\n",
        "smn = SMOTEENN(sampling_strategy = 'minority', random_state=seed)\n",
        "X2_train_smn, y2_train_smn = smn.fit_resample(X2_train, y2_train)\n",
        "print(y2_train_smn.value_counts())\n",
        "# Initiating XGBClassifier\n",
        "xgb_smn = XGBClassifier(random_state=seed)\n",
        "xgb_smn.fit(X2_train_smn, y2_train_smn)\n",
        "y2_pred_smn = xgb_smn.predict(X2_test)\n",
        "print(f\"XGB-SMOTEEN Applied: \\n\", classification_report(y2_test, y2_pred_smn))\n",
        "fhalf_score_smn = fbeta_score(y2_test, y2_pred_smn, beta=0.5)\n",
        "print(f\"F0.5 Score: {fhalf_score_smn}\")\n",
        "f2_score_smn = fbeta_score(y2_test, y2_pred_smn, beta=2)\n",
        "print(f\"F2 Score: {f2_score_smn}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1Jpaq4_gdJT"
      },
      "source": [
        "##### SGDClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RrDo646Kggzu",
        "outputId": "d74dce52-052a-47ef-b998-d3ad76e9dd98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "y\n",
            "0    2020\n",
            "1    2020\n",
            "Name: count, dtype: int64\n",
            "SGDClassifier Applied with RandomUnderSampler: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.82      0.89     11124\n",
            "           1       0.26      0.79      0.39       876\n",
            "\n",
            "    accuracy                           0.82     12000\n",
            "   macro avg       0.62      0.80      0.64     12000\n",
            "weighted avg       0.93      0.82      0.86     12000\n",
            "\n",
            "F0.5 Score: 0.2948234487487144\n",
            "F2 Score: 0.5546597871654305\n",
            "y\n",
            "1    25980\n",
            "0    25980\n",
            "Name: count, dtype: int64\n",
            "SGD-SMOTE Applied: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.65      0.78     11124\n",
            "           1       0.15      0.81      0.26       876\n",
            "\n",
            "    accuracy                           0.66     12000\n",
            "   macro avg       0.57      0.73      0.52     12000\n",
            "weighted avg       0.92      0.66      0.74     12000\n",
            "\n",
            "F0.5 Score: 0.1827080770807708\n",
            "F2 Score: 0.5546597871654305\n",
            "y\n",
            "1    25369\n",
            "0    25369\n",
            "Name: count, dtype: int64\n",
            "SGD-SMOTE TOMEK Applied: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.90      0.93     11124\n",
            "           1       0.29      0.50      0.36       876\n",
            "\n",
            "    accuracy                           0.87     12000\n",
            "   macro avg       0.62      0.70      0.65     12000\n",
            "weighted avg       0.91      0.87      0.89     12000\n",
            "\n",
            "F0.5 Score: 0.31214121699196323\n",
            "F2 Score: 0.4326636164710563\n",
            "y\n",
            "1    22497\n",
            "0    17384\n",
            "Name: count, dtype: int64\n",
            "SGD-SMOTEEN Applied: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.86      0.90     11124\n",
            "           1       0.19      0.42      0.26       876\n",
            "\n",
            "    accuracy                           0.83     12000\n",
            "   macro avg       0.57      0.64      0.58     12000\n",
            "weighted avg       0.89      0.83      0.85     12000\n",
            "\n",
            "F0.5 Score: 0.21390682656826568\n",
            "F2 Score: 0.34017971758664955\n"
          ]
        }
      ],
      "source": [
        "# 1. Apply RandomUnderSampler\n",
        "rus = RandomUnderSampler(sampling_strategy='majority', random_state=seed)\n",
        "X2_train_rus, y2_train_rus = rus.fit_resample(X2_train, y2_train)\n",
        "print(y2_train_rus.value_counts())\n",
        "\n",
        "# Initiate SGDClassifier\n",
        "sgd_rus = SGDClassifier(random_state=seed)\n",
        "sgd_rus.fit(X2_train_rus, y2_train_rus)\n",
        "y_pred = sgd_rus.predict(X2_test)\n",
        "print(f\"SGDClassifier Applied with RandomUnderSampler: \\n\", classification_report(y2_test, y2_pred))\n",
        "# the result is skewed, since the data is imbalanced\n",
        "fhalf_score = fbeta_score(y2_test, y2_pred, beta=0.5)\n",
        "print(f\"F0.5 Score: {fhalf_score}\")\n",
        "f2_score = fbeta_score(y2_test, y2_pred, beta=2)\n",
        "print(f\"F2 Score: {f2_score}\")\n",
        "\n",
        "# 2. Apply SMOTE (Synthetic Minotiry Oversampling Technique)\n",
        "sm = SMOTE(sampling_strategy = 'minority', random_state=seed)\n",
        "X2_train_sm, y2_train_sm = sm.fit_resample(X2_train, y2_train)\n",
        "print(y2_train_sm.value_counts())\n",
        "# Initiating SGDClassifier\n",
        "sgd_sm = SGDClassifier(random_state=seed)\n",
        "sgd_sm.fit(X2_train_sm, y2_train_sm)\n",
        "y2_pred_sm = sgd_sm.predict(X2_test)\n",
        "print(f\"SGD-SMOTE Applied: \\n\", classification_report(y2_test, y2_pred_sm))\n",
        "fhalf_score_sm = fbeta_score(y2_test, y2_pred_sm, beta=0.5)\n",
        "print(f\"F0.5 Score: {fhalf_score_sm}\")\n",
        "f2_score_sm = fbeta_score(y2_test, y2_pred, beta=2)\n",
        "print(f\"F2 Score: {f2_score_sm}\")\n",
        "\n",
        "# 3. Apply SMOTE-TOMEK\n",
        "smt = SMOTETomek(sampling_strategy = 'minority', random_state=seed)\n",
        "X2_train_smt, y2_train_smt = smt.fit_resample(X2_train, y2_train)\n",
        "print(y2_train_smt.value_counts())\n",
        "# Initiating SGDClassifier\n",
        "sgd_smt = SGDClassifier(random_state=seed)\n",
        "sgd_smt.fit(X2_train_smt, y2_train_smt)\n",
        "y2_pred_smt = sgd_smt.predict(X2_test)\n",
        "print(f\"SGD-SMOTE TOMEK Applied: \\n\", classification_report(y2_test, y2_pred_smt))\n",
        "fhalf_score_smt = fbeta_score(y2_test, y2_pred_smt, beta=0.5)\n",
        "print(f\"F0.5 Score: {fhalf_score_smt}\")\n",
        "f2_score_smt = fbeta_score(y2_test, y2_pred_smt, beta=2)\n",
        "print(f\"F2 Score: {f2_score_smt}\")\n",
        "\n",
        "# 4. Apply SMOTEEN to balance the classes\n",
        "smn = SMOTEENN(sampling_strategy = 'minority', random_state=seed)\n",
        "X2_train_smn, y2_train_smn = smn.fit_resample(X2_train, y2_train)\n",
        "print(y2_train_smn.value_counts())\n",
        "# Initiating SGDClassifier\n",
        "sgd_smn = SGDClassifier(random_state=seed)\n",
        "sgd_smn.fit(X2_train_smn, y2_train_smn)\n",
        "y2_pred_smn = sgd_smn.predict(X2_test)\n",
        "print(f\"SGD-SMOTEEN Applied: \\n\", classification_report(y2_test, y2_pred_smn))\n",
        "fhalf_score_smn = fbeta_score(y2_test, y2_pred_smn, beta=0.5)\n",
        "print(f\"F0.5 Score: {fhalf_score_smn}\")\n",
        "f2_score_smn = fbeta_score(y2_test, y2_pred_smn, beta=2)\n",
        "print(f\"F2 Score: {f2_score_smn}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sb4yh1JbghbG"
      },
      "source": [
        "##### SVC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "miZt09L3gifO",
        "outputId": "71445ebf-50a1-403a-c75c-dcd938045c38"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "y\n",
            "0    2020\n",
            "1    2020\n",
            "Name: count, dtype: int64\n",
            "SVC Applied with RandomUnderSampler: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.86      0.91     11124\n",
            "           1       0.25      0.62      0.36       876\n",
            "\n",
            "    accuracy                           0.84     12000\n",
            "   macro avg       0.61      0.74      0.63     12000\n",
            "weighted avg       0.91      0.84      0.87     12000\n",
            "\n",
            "F0.5 Score: 0.288135593220339\n",
            "F2 Score: 0.4818423383525244\n",
            "y\n",
            "1    25980\n",
            "0    25980\n",
            "Name: count, dtype: int64\n",
            "SVC-SMOTE Applied: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.88      0.92     11124\n",
            "           1       0.27      0.58      0.37       876\n",
            "\n",
            "    accuracy                           0.86     12000\n",
            "   macro avg       0.62      0.73      0.64     12000\n",
            "weighted avg       0.91      0.86      0.88     12000\n",
            "\n",
            "F0.5 Score: 0.1827080770807708\n",
            "F2 Score: 0.5546597871654305\n",
            "y\n",
            "1    25369\n",
            "0    25369\n",
            "Name: count, dtype: int64\n",
            "SVC-SMOTE TOMEK Applied: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.88      0.92     11124\n",
            "           1       0.27      0.58      0.37       876\n",
            "\n",
            "    accuracy                           0.86     12000\n",
            "   macro avg       0.62      0.73      0.64     12000\n",
            "weighted avg       0.91      0.86      0.88     12000\n",
            "\n",
            "F0.5 Score: 0.31214121699196323\n",
            "F2 Score: 0.4326636164710563\n",
            "y\n",
            "1    22497\n",
            "0    17384\n",
            "Name: count, dtype: int64\n",
            "SVC-SMOTEEN Applied: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.83      0.89     11124\n",
            "           1       0.23      0.64      0.33       876\n",
            "\n",
            "    accuracy                           0.81     12000\n",
            "   macro avg       0.60      0.73      0.61     12000\n",
            "weighted avg       0.91      0.81      0.85     12000\n",
            "\n",
            "F0.5 Score: 0.21390682656826568\n",
            "F2 Score: 0.34017971758664955\n"
          ]
        }
      ],
      "source": [
        "# 1. Apply RandomUnderSampler\n",
        "rus = RandomUnderSampler(sampling_strategy='majority', random_state=seed)\n",
        "X2_train_rus, y2_train_rus = rus.fit_resample(X2_train, y2_train)\n",
        "print(y2_train_rus.value_counts())\n",
        "\n",
        "# Initiate SVC\n",
        "svc_rus = SVC(random_state=seed)\n",
        "svc_rus.fit(X2_train_rus, y2_train_rus)\n",
        "y2_pred = svc_rus.predict(X2_test)\n",
        "print(f\"SVC Applied with RandomUnderSampler: \\n\", classification_report(y2_test, y2_pred))\n",
        "# the result is skewed, since the data is imbalanced\n",
        "fhalf_score = fbeta_score(y2_test, y2_pred, beta=0.5)\n",
        "print(f\"F0.5 Score: {fhalf_score}\")\n",
        "f2_score = fbeta_score(y2_test, y2_pred, beta=2)\n",
        "print(f\"F2 Score: {f2_score}\")\n",
        "\n",
        "# 2. Apply SMOTE (Synthetic Minotiry Oversampling Technique)\n",
        "sm = SMOTE(sampling_strategy = 'minority', random_state=seed)\n",
        "X2_train_sm, y2_train_sm = sm.fit_resample(X2_train, y2_train)\n",
        "print(y2_train_sm.value_counts())\n",
        "# Initiating SVC\n",
        "svc_sm = SVC(random_state=seed)\n",
        "svc_sm.fit(X2_train_sm, y2_train_sm)\n",
        "y2_pred_sm = svc_sm.predict(X2_test)\n",
        "print(f\"SVC-SMOTE Applied: \\n\", classification_report(y2_test, y2_pred_sm))\n",
        "fhalf_score = fbeta_score(y2_test, y2_pred_sm, beta=0.5)\n",
        "print(f\"F0.5 Score: {fhalf_score_sm}\")\n",
        "f2_score = fbeta_score(y2_test, y2_pred_sm, beta=2)\n",
        "print(f\"F2 Score: {f2_score_sm}\")\n",
        "\n",
        "# 3. Apply SMOTE-TOMEK\n",
        "smt = SMOTETomek(sampling_strategy = 'minority', random_state=seed)\n",
        "X2_train_smt, y2_train_smt = smt.fit_resample(X2_train, y2_train)\n",
        "print(y2_train_smt.value_counts())\n",
        "# Initiating SVC\n",
        "svc_smt = SVC(random_state=seed)\n",
        "svc_smt.fit(X2_train_smt, y2_train_smt)\n",
        "y2_pred_smt = svc_smt.predict(X2_test)\n",
        "print(f\"SVC-SMOTE TOMEK Applied: \\n\", classification_report(y2_test, y2_pred_smt))\n",
        "fhalf_score = fbeta_score(y2_test, y2_pred_smt, beta=0.5)\n",
        "print(f\"F0.5 Score: {fhalf_score_smt}\")\n",
        "f2_score = fbeta_score(y2_test, y2_pred_smt, beta=2)\n",
        "print(f\"F2 Score: {f2_score_smt}\")\n",
        "\n",
        "# 4. Apply SMOTEEN to balance the classes\n",
        "smn = SMOTEENN(sampling_strategy = 'minority', random_state=seed)\n",
        "X2_train_smn, y2_train_smn = smn.fit_resample(X2_train, y2_train)\n",
        "print(y2_train_smn.value_counts())\n",
        "# Initiating SVC\n",
        "svc_smn = SVC(random_state=seed)\n",
        "svc_smn.fit(X2_train_smn, y2_train_smn)\n",
        "y2_pred_smn = svc_smn.predict(X2_test)\n",
        "print(f\"SVC-SMOTEEN Applied: \\n\", classification_report(y2_test, y2_pred_smn))\n",
        "fhalf_score = fbeta_score(y2_test, y2_pred_smn, beta=0.5)\n",
        "print(f\"F0.5 Score: {fhalf_score_smn}\")\n",
        "f2_score = fbeta_score(y2_test, y2_pred_smn, beta=2)\n",
        "print(f\"F2 Score: {f2_score_smn}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XznTFcoDjEgz"
      },
      "source": [
        "##### LGBMClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "doKbfb6pjGlj",
        "outputId": "e95ea0d8-4b44-4e3e-9d82-09c4a56708cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "y\n",
            "0    2020\n",
            "1    2020\n",
            "Name: count, dtype: int64\n",
            "[LightGBM] [Info] Number of positive: 2020, number of negative: 2020\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000354 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 657\n",
            "[LightGBM] [Info] Number of data points in the train set: 4040, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "LGBMClassifier Applied with RandomUnderSampler: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.83      0.90     11124\n",
            "           1       0.27      0.80      0.41       876\n",
            "\n",
            "    accuracy                           0.83     12000\n",
            "   macro avg       0.63      0.82      0.65     12000\n",
            "weighted avg       0.93      0.83      0.87     12000\n",
            "\n",
            "F0.5 Score: 0.31587959625090123\n",
            "F2 Score: 0.5784782967486384\n",
            "y\n",
            "1    25980\n",
            "0    25980\n",
            "Name: count, dtype: int64\n",
            "[LightGBM] [Info] Number of positive: 25980, number of negative: 25980\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004629 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 687\n",
            "[LightGBM] [Info] Number of data points in the train set: 51960, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "LGBM-SMOTE Applied: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.91      0.93     11124\n",
            "           1       0.32      0.55      0.40       876\n",
            "\n",
            "    accuracy                           0.88     12000\n",
            "   macro avg       0.64      0.73      0.67     12000\n",
            "weighted avg       0.92      0.88      0.89     12000\n",
            "\n",
            "F0.5 Score: 0.3460207612456747\n",
            "F2 Score: 0.4781829049611476\n",
            "y\n",
            "1    25369\n",
            "0    25369\n",
            "Name: count, dtype: int64\n",
            "[LightGBM] [Info] Number of positive: 25369, number of negative: 25369\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004580 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 687\n",
            "[LightGBM] [Info] Number of data points in the train set: 50738, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "LGBM-SMOTE TOMEK Applied: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.91      0.93     11124\n",
            "           1       0.32      0.55      0.40       876\n",
            "\n",
            "    accuracy                           0.88     12000\n",
            "   macro avg       0.64      0.73      0.67     12000\n",
            "weighted avg       0.92      0.88      0.90     12000\n",
            "\n",
            "F0.5 Score: 0.31214121699196323\n",
            "F2 Score: 0.4806541683286797\n",
            "y\n",
            "1    22497\n",
            "0    17384\n",
            "Name: count, dtype: int64\n",
            "[LightGBM] [Info] Number of positive: 22497, number of negative: 17384\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004933 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 684\n",
            "[LightGBM] [Info] Number of data points in the train set: 39881, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.564103 -> initscore=0.257832\n",
            "[LightGBM] [Info] Start training from score 0.257832\n",
            "LGBM-SMOTEEN Applied: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.87      0.92     11124\n",
            "           1       0.29      0.68      0.41       876\n",
            "\n",
            "    accuracy                           0.86     12000\n",
            "   macro avg       0.63      0.78      0.66     12000\n",
            "weighted avg       0.92      0.86      0.88     12000\n",
            "\n",
            "F0.5 Score: 0.32981530343007914\n",
            "F2 Score: 0.5396654074473827\n"
          ]
        }
      ],
      "source": [
        "# 1. Apply RandomUnderSampler\n",
        "rus = RandomUnderSampler(sampling_strategy='majority', random_state=seed)\n",
        "X2_train_rus, y2_train_rus = rus.fit_resample(X2_train, y2_train)\n",
        "print(y2_train_rus.value_counts())\n",
        "\n",
        "# Initiate LGBMClassifier\n",
        "lgbm_rus = LGBMClassifier(random_state=seed)\n",
        "lgbm_rus.fit(X2_train_rus, y2_train_rus)\n",
        "y2_pred = lgbm_rus.predict(X2_test)\n",
        "print(f\"LGBMClassifier Applied with RandomUnderSampler: \\n\", classification_report(y2_test, y2_pred))\n",
        "# the result is skewed, since the data is imbalanced\n",
        "fhalf_score = fbeta_score(y2_test, y2_pred, beta=0.5)\n",
        "print(f\"F0.5 Score: {fhalf_score}\")\n",
        "f2_score = fbeta_score(y2_test, y2_pred, beta=2)\n",
        "print(f\"F2 Score: {f2_score}\")\n",
        "\n",
        "# 2. Apply SMOTE (Synthetic Minotiry Oversampling Technique)\n",
        "sm = SMOTE(sampling_strategy = 'minority', random_state=seed)\n",
        "X2_train_sm, y2_train_sm = sm.fit_resample(X2_train, y2_train)\n",
        "print(y2_train_sm.value_counts())\n",
        "# Initiating LGBMClassifier\n",
        "lgbm_sm = LGBMClassifier(random_state=seed)\n",
        "lgbm_sm.fit(X2_train_sm, y2_train_sm)\n",
        "y2_pred_sm = lgbm_sm.predict(X2_test)\n",
        "print(f\"LGBM-SMOTE Applied: \\n\", classification_report(y2_test, y2_pred_sm))\n",
        "fhalf_score_sm = fbeta_score(y2_test, y2_pred_sm, beta=0.5)\n",
        "print(f\"F0.5 Score: {fhalf_score_sm}\")\n",
        "f2_score_sm = fbeta_score(y2_test, y2_pred_sm, beta=2)\n",
        "print(f\"F2 Score: {f2_score_sm}\")\n",
        "\n",
        "\n",
        "# 3. Apply SMOTE-TOMEK\n",
        "smt = SMOTETomek(sampling_strategy = 'minority', random_state=seed)\n",
        "X2_train_smt, y2_train_smt = smt.fit_resample(X2_train, y2_train)\n",
        "print(y2_train_smt.value_counts())\n",
        "# Initiating LGBMClassifier\n",
        "lgbm_smt = LGBMClassifier(random_state=seed)\n",
        "lgbm_smt.fit(X2_train_smt, y2_train_smt)\n",
        "y2_pred_smt = lgbm_smt.predict(X2_test)\n",
        "print(f\"LGBM-SMOTE TOMEK Applied: \\n\", classification_report(y2_test, y2_pred_smt))\n",
        "fhalf_score = fbeta_score(y2_test, y2_pred_smt, beta=0.5)\n",
        "print(f\"F0.5 Score: {fhalf_score_smt}\")\n",
        "f2_score_smt = fbeta_score(y2_test, y2_pred_smt, beta=2)\n",
        "print(f\"F2 Score: {f2_score_smt}\")\n",
        "\n",
        "# 4. Apply SMOTEEN to balance the classes\n",
        "smn = SMOTEENN(sampling_strategy = 'minority', random_state=seed)\n",
        "X2_train_smn, y2_train_smn = smn.fit_resample(X2_train, y2_train)\n",
        "print(y2_train_smn.value_counts())\n",
        "# Initiating LGBMClassifier\n",
        "lgbm_smn = LGBMClassifier(random_state=seed)\n",
        "lgbm_smn.fit(X2_train_smn, y2_train_smn)\n",
        "y2_pred_smn = lgbm_smn.predict(X2_test)\n",
        "print(f\"LGBM-SMOTEEN Applied: \\n\", classification_report(y2_test, y2_pred_smn))\n",
        "fhalf_score_smn = fbeta_score(y2_test, y2_pred_smn, beta=0.5)\n",
        "print(f\"F0.5 Score: {fhalf_score_smn}\")\n",
        "f2_score_smn = fbeta_score(y2_test, y2_pred_smn, beta=2)\n",
        "print(f\"F2 Score: {f2_score_smn}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "InNnn3pRjq3w"
      },
      "source": [
        "##### DecisionTreeClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHnHLWusjwi7",
        "outputId": "39167f5f-9bc1-4e13-f8be-4593fe1aeddb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "y\n",
            "0    2020\n",
            "1    2020\n",
            "Name: count, dtype: int64\n",
            "DecisionTreeClassifier Applied with RandomUnderSampler: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.72      0.83     11124\n",
            "           1       0.17      0.71      0.27       876\n",
            "\n",
            "    accuracy                           0.72     12000\n",
            "   macro avg       0.57      0.72      0.55     12000\n",
            "weighted avg       0.91      0.72      0.79     12000\n",
            "\n",
            "F0.5 Score: 0.19787152689268417\n",
            "F2 Score: 0.4307713651498335\n",
            "y\n",
            "1    25980\n",
            "0    25980\n",
            "Name: count, dtype: int64\n",
            "DTC-SMOTE Applied: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.88      0.91     11124\n",
            "           1       0.21      0.41      0.28       876\n",
            "\n",
            "    accuracy                           0.85     12000\n",
            "   macro avg       0.58      0.64      0.60     12000\n",
            "weighted avg       0.90      0.85      0.87     12000\n",
            "\n",
            "F0.5 Score: 0.23516163222045575\n",
            "F2 Score: 0.3431941221964424\n",
            "y\n",
            "1    25369\n",
            "0    25369\n",
            "Name: count, dtype: int64\n",
            "DTC-SMOTE TOMEK Applied: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.88      0.92     11124\n",
            "           1       0.22      0.44      0.30       876\n",
            "\n",
            "    accuracy                           0.85     12000\n",
            "   macro avg       0.59      0.66      0.61     12000\n",
            "weighted avg       0.90      0.85      0.87     12000\n",
            "\n",
            "F0.5 Score: 0.24779449922158797\n",
            "F2 Score: 0.3664620107444359\n",
            "y\n",
            "1    22497\n",
            "0    17384\n",
            "Name: count, dtype: int64\n",
            "DTC-SMOTEEN Applied: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.85      0.90     11124\n",
            "           1       0.23      0.60      0.34       876\n",
            "\n",
            "    accuracy                           0.83     12000\n",
            "   macro avg       0.60      0.72      0.62     12000\n",
            "weighted avg       0.91      0.83      0.86     12000\n",
            "\n",
            "F0.5 Score: 0.26629327902240324\n",
            "F2 Score: 0.45557491289198604\n"
          ]
        }
      ],
      "source": [
        "# 1. Apply RandomUnderSampler\n",
        "rus = RandomUnderSampler(sampling_strategy='majority', random_state=seed)\n",
        "X2_train_rus, y2_train_rus = rus.fit_resample(X2_train, y2_train)\n",
        "print(y2_train_rus.value_counts())\n",
        "\n",
        "# Initiate DecisionTreeClassifier\n",
        "dtc_rus = DecisionTreeClassifier(random_state=seed)\n",
        "dtc_rus.fit(X2_train_rus, y2_train_rus)\n",
        "y2_pred = dtc_rus.predict(X2_test)\n",
        "print(f\"DecisionTreeClassifier Applied with RandomUnderSampler: \\n\", classification_report(y2_test, y2_pred))\n",
        "# the result is skewed, since the data is imbalancedfhalf_score = fbeta_score(y2_test, y2_pred_sm, beta=0.5)\n",
        "fhalf_score = fbeta_score(y2_test, y2_pred, beta=0.5)\n",
        "print(f\"F0.5 Score: {fhalf_score}\")\n",
        "f2_score = fbeta_score(y2_test, y2_pred, beta=2)\n",
        "print(f\"F2 Score: {f2_score}\")\n",
        "\n",
        "\n",
        "# 2. Apply SMOTE (Synthetic Minotiry Oversampling Technique)\n",
        "sm = SMOTE(sampling_strategy = 'minority', random_state=seed)\n",
        "X2_train_sm, y2_train_sm = sm.fit_resample(X2_train, y2_train)\n",
        "print(y2_train_sm.value_counts())\n",
        "# Initiating DTClassifier\n",
        "dtc_sm = DecisionTreeClassifier(random_state=seed)\n",
        "dtc_sm.fit(X2_train_sm, y2_train_sm)\n",
        "y2_pred_sm = dtc_sm.predict(X2_test)\n",
        "print(f\"DTC-SMOTE Applied: \\n\", classification_report(y2_test, y2_pred_sm))\n",
        "fhalf_score_sm = fbeta_score(y2_test, y2_pred_sm, beta=0.5)\n",
        "print(f\"F0.5 Score: {fhalf_score_sm}\")\n",
        "f2_score_sm = fbeta_score(y2_test, y2_pred_sm, beta=2)\n",
        "print(f\"F2 Score: {f2_score_sm}\")\n",
        "\n",
        "\n",
        "# 3. Apply SMOTE-TOMEK\n",
        "smt = SMOTETomek(sampling_strategy = 'minority', random_state=seed)\n",
        "X2_train_smt, y1_train_smt = smt.fit_resample(X2_train, y2_train)\n",
        "print(y2_train_smt.value_counts())\n",
        "# Initiating DTClassifier\n",
        "dtc_smt = DecisionTreeClassifier(random_state=seed)\n",
        "dtc_smt.fit(X2_train_smt, y1_train_smt)\n",
        "y2_pred_smt = dtc_smt.predict(X2_test)\n",
        "print(f\"DTC-SMOTE TOMEK Applied: \\n\", classification_report(y2_test, y2_pred_smt))\n",
        "fhalf_score_smt = fbeta_score(y2_test, y2_pred_smt, beta=0.5)\n",
        "print(f\"F0.5 Score: {fhalf_score_smt}\")\n",
        "f2_score_smt = fbeta_score(y2_test, y2_pred_smt, beta=2)\n",
        "print(f\"F2 Score: {f2_score_smt}\")\n",
        "\n",
        "# 4. Apply SMOTEEN to balance the classes\n",
        "smn = SMOTEENN(sampling_strategy = 'minority', random_state=seed)\n",
        "X2_train_smn, y2_train_smn = smn.fit_resample(X2_train, y2_train)\n",
        "print(y2_train_smn.value_counts())\n",
        "# Initiating DTClassifier\n",
        "dtc_smn = DecisionTreeClassifier(random_state=seed)\n",
        "dtc_smn.fit(X2_train_smn, y2_train_smn)\n",
        "y2_pred_smn = dtc_smn.predict(X2_test)\n",
        "print(f\"DTC-SMOTEEN Applied: \\n\", classification_report(y2_test, y2_pred_smn))\n",
        "fhalf_score_smn = fbeta_score(y2_test, y2_pred_smn, beta=0.5)\n",
        "print(f\"F0.5 Score: {fhalf_score_smn}\")\n",
        "f2_score_smn = fbeta_score(y2_test, y2_pred_smn, beta=2)\n",
        "print(f\"F2 Score: {f2_score_smn}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5RtxfI6deGZ"
      },
      "source": [
        "##### Perceptron"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7EzjLCZZd51_",
        "outputId": "adfbc55e-7d6d-4180-b417-5dced1f74bae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "y\n",
            "0    2020\n",
            "1    2020\n",
            "Name: count, dtype: int64\n",
            "Perceptron: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.30      0.46     11124\n",
            "           1       0.09      0.87      0.16       876\n",
            "\n",
            "    accuracy                           0.34     12000\n",
            "   macro avg       0.53      0.58      0.31     12000\n",
            "weighted avg       0.90      0.34      0.44     12000\n",
            "\n",
            "F0.5 Score: 0.10857142857142857\n",
            "F2 Score: 0.31574574158703783\n",
            "y\n",
            "1    25980\n",
            "0    25980\n",
            "Name: count, dtype: int64\n",
            "DTC-SMOTE Applied: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.27      0.42     11124\n",
            "           1       0.09      0.92      0.16       876\n",
            "\n",
            "    accuracy                           0.32     12000\n",
            "   macro avg       0.53      0.59      0.29     12000\n",
            "weighted avg       0.91      0.32      0.40     12000\n",
            "\n",
            "F0.5 Score: 0.11003280481137233\n",
            "F2 Score: 0.3238133547868061\n",
            "y\n",
            "1    25369\n",
            "0    25369\n",
            "Name: count, dtype: int64\n",
            "PT-SMOTE TOMEK Applied: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.23      0.37     11124\n",
            "           1       0.09      0.93      0.16       876\n",
            "\n",
            "    accuracy                           0.28     12000\n",
            "   macro avg       0.53      0.58      0.27     12000\n",
            "weighted avg       0.91      0.28      0.36     12000\n",
            "\n",
            "F0.5 Score: 0.10594543940024989\n",
            "F2 Score: 0.3157731398867251\n",
            "y\n",
            "1    22497\n",
            "0    17384\n",
            "Name: count, dtype: int64\n",
            "DTC-SMOTEEN Applied: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.91      0.93     11124\n",
            "           1       0.22      0.32      0.26       876\n",
            "\n",
            "    accuracy                           0.87     12000\n",
            "   macro avg       0.58      0.61      0.59     12000\n",
            "weighted avg       0.89      0.87      0.88     12000\n",
            "\n",
            "F0.5 Score: 0.23043766578249336\n",
            "F2 Score: 0.29000625912789485\n"
          ]
        }
      ],
      "source": [
        "# 1. Apply RandomUnderSampler\n",
        "rus = RandomUnderSampler(sampling_strategy='majority', random_state=seed)\n",
        "X2_train_rus, y2_train_rus = rus.fit_resample(X2_train, y2_train)\n",
        "print(y2_train_rus.value_counts())\n",
        "\n",
        "# Initiate DecisionTreeClassifier\n",
        "pt_rus = Perceptron(random_state=seed)\n",
        "pt_rus.fit(X2_train_rus, y2_train_rus)\n",
        "y2_pred = pt_rus.predict(X2_test)\n",
        "print(f\"Perceptron: \\n\", classification_report(y2_test, y2_pred))\n",
        "# the result is skewed, since the data is imbalancedfhalf_score = fbeta_score(y2_test, y2_pred_sm, beta=0.5)\n",
        "fhalf_score = fbeta_score(y2_test, y2_pred, beta=0.5)\n",
        "print(f\"F0.5 Score: {fhalf_score}\")\n",
        "f2_score = fbeta_score(y2_test, y2_pred, beta=2)\n",
        "print(f\"F2 Score: {f2_score}\")\n",
        "\n",
        "\n",
        "# 2. Apply SMOTE (Synthetic Minotiry Oversampling Technique)\n",
        "sm = SMOTE(sampling_strategy = 'minority', random_state=seed)\n",
        "X2_train_sm, y2_train_sm = sm.fit_resample(X2_train, y2_train)\n",
        "print(y2_train_sm.value_counts())\n",
        "# Initiating Perceptron\n",
        "pt_sm = Perceptron(random_state=seed)\n",
        "pt_sm.fit(X2_train_sm, y2_train_sm)\n",
        "y2_pred_sm = pt_sm.predict(X2_test)\n",
        "print(f\"DTC-SMOTE Applied: \\n\", classification_report(y2_test, y2_pred_sm))\n",
        "fhalf_score_sm = fbeta_score(y2_test, y2_pred_sm, beta=0.5)\n",
        "print(f\"F0.5 Score: {fhalf_score_sm}\")\n",
        "f2_score_sm = fbeta_score(y2_test, y2_pred_sm, beta=2)\n",
        "print(f\"F2 Score: {f2_score_sm}\")\n",
        "\n",
        "\n",
        "# 3. Apply SMOTE-TOMEK\n",
        "smt = SMOTETomek(sampling_strategy = 'minority', random_state=seed)\n",
        "X2_train_smt, y1_train_smt = smt.fit_resample(X2_train, y2_train)\n",
        "print(y2_train_smt.value_counts())\n",
        "# Initiating Perceptron\n",
        "pt_smt = Perceptron(random_state=seed)\n",
        "pt_smt.fit(X2_train_smt, y1_train_smt)\n",
        "y2_pred_smt = pt_smt.predict(X2_test)\n",
        "print(f\"PT-SMOTE TOMEK Applied: \\n\", classification_report(y2_test, y2_pred_smt))\n",
        "fhalf_score_smt = fbeta_score(y2_test, y2_pred_smt, beta=0.5)\n",
        "print(f\"F0.5 Score: {fhalf_score_smt}\")\n",
        "f2_score_smt = fbeta_score(y2_test, y2_pred_smt, beta=2)\n",
        "print(f\"F2 Score: {f2_score_smt}\")\n",
        "\n",
        "# 4. Apply SMOTEEN to balance the classes\n",
        "smn = SMOTEENN(sampling_strategy = 'minority', random_state=seed)\n",
        "X2_train_smn, y2_train_smn = smn.fit_resample(X2_train, y2_train)\n",
        "print(y2_train_smn.value_counts())\n",
        "# Initiating Perceptron\n",
        "pt_smn = Perceptron(random_state=seed)\n",
        "pt_smn.fit(X2_train_smn, y2_train_smn)\n",
        "y2_pred_smn = pt_smn.predict(X2_test)\n",
        "print(f\"DTC-SMOTEEN Applied: \\n\", classification_report(y2_test, y2_pred_smn))\n",
        "fhalf_score_smn = fbeta_score(y2_test, y2_pred_smn, beta=0.5)\n",
        "print(f\"F0.5 Score: {fhalf_score_smn}\")\n",
        "f2_score_smn = fbeta_score(y2_test, y2_pred_smn, beta=2)\n",
        "print(f\"F2 Score: {f2_score_smn}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5JjU7GGxdb1"
      },
      "source": [
        "#### Applying Ensemble for RUS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80HzpD5I4Inv",
        "outputId": "158a6caa-43c9-4bd3-8221-2fb950c3cb06"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Evaluating with RandomUnderSampler ---\n",
            "Cross-validated F1 scores with RandomUnderSampler: [0.36407767 0.36668595 0.37933059 0.34613181 0.37206573]\n",
            "Average F1 score with RandomUnderSampler: 0.3656583482928803\n",
            "Evaluation with RandomUnderSampler on the test set:\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Non-subscriber       0.98      0.81      0.89     11124\n",
            "    Subscriber       0.25      0.78      0.37       876\n",
            "\n",
            "      accuracy                           0.81     12000\n",
            "     macro avg       0.61      0.80      0.63     12000\n",
            "  weighted avg       0.93      0.81      0.85     12000\n",
            "\n",
            "F0.5 Score: 0.2846782260753585\n",
            "F1 Score: 0.37363238512035013\n",
            "F2 Score: 0.5434436664544876\n",
            "\n",
            "--- Evaluating with RandomOverSampler ---\n",
            "Cross-validated F1 scores with RandomOverSampler: [0.43047619 0.44588344 0.47178538 0.4330855  0.47383444]\n",
            "Average F1 score with RandomOverSampler: 0.4510129921768128\n",
            "Evaluation with RandomOverSampler on the test set:\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Non-subscriber       0.97      0.92      0.94     11124\n",
            "    Subscriber       0.38      0.61      0.47       876\n",
            "\n",
            "      accuracy                           0.90     12000\n",
            "     macro avg       0.67      0.77      0.71     12000\n",
            "  weighted avg       0.92      0.90      0.91     12000\n",
            "\n",
            "F0.5 Score: 0.4097732843137255\n",
            "F1 Score: 0.4674530362603757\n",
            "F2 Score: 0.5440309131584299\n",
            "\n",
            "--- Evaluating with SMOTEENN ---\n",
            "Cross-validated F1 scores with SMOTEENN: [0.41568627 0.42647059 0.44411103 0.40416048 0.44561934]\n",
            "Average F1 score with SMOTEENN: 0.4272095402664764\n",
            "Evaluation with SMOTEENN on the test set:\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Non-subscriber       0.97      0.88      0.93     11124\n",
            "    Subscriber       0.32      0.71      0.44       876\n",
            "\n",
            "      accuracy                           0.87     12000\n",
            "     macro avg       0.65      0.80      0.68     12000\n",
            "  weighted avg       0.93      0.87      0.89     12000\n",
            "\n",
            "F0.5 Score: 0.3613826815642458\n",
            "F1 Score: 0.44278074866310163\n",
            "F2 Score: 0.571507454445058\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.metrics import classification_report, make_scorer, fbeta_score\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
        "from imblearn.combine import SMOTEENN\n",
        "from imblearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Define the ensemble models to use in VotingClassifier\n",
        "classifiers = [\n",
        "    ('rf', RandomForestClassifier(random_state=42)),\n",
        "    ('gb', GradientBoostingClassifier(random_state=42)),\n",
        "    ('svc', SVC(probability=True, random_state=42)),  # Setting probability=True for voting\n",
        "    ('logreg', LogisticRegression(random_state=42)),\n",
        "    ('dt', DecisionTreeClassifier(random_state=42))\n",
        "]\n",
        "\n",
        "# Define the VotingClassifier for soft voting\n",
        "voting_clf = VotingClassifier(estimators=classifiers, voting='soft')\n",
        "\n",
        "# Evaluation function to calculate F0.5, F1, and F2 scores\n",
        "def evaluate_model(model, X_train, y_train, X_test, y_test):\n",
        "    model.fit(X2_train, y2_train)\n",
        "    y2_pred = model.predict(X2_test)\n",
        "    print(classification_report(y2_test, y2_pred, target_names=['Non-subscriber', 'Subscriber']))\n",
        "\n",
        "    # F0.5, F1, and F2 scores\n",
        "    f0_5 = fbeta_score(y2_test, y2_pred, beta=0.5)\n",
        "    f1 = fbeta_score(y2_test, y2_pred, beta=1.0)\n",
        "    f2 = fbeta_score(y2_test, y2_pred, beta=2.0)\n",
        "\n",
        "    print(f'F0.5 Score: {f0_5}')\n",
        "    print(f'F1 Score: {f1}')\n",
        "    print(f'F2 Score: {f2}')\n",
        "\n",
        "# Apply each resampling technique with the VotingClassifier\n",
        "resamplers = {\n",
        "    \"RandomUnderSampler\": RandomUnderSampler(sampling_strategy='majority', random_state=seed),\n",
        "    \"RandomOverSampler\": RandomOverSampler(sampling_strategy='minority', random_state=seed),\n",
        "    \"SMOTEENN\": SMOTEENN(sampling_strategy='auto', random_state=seed)\n",
        "}\n",
        "\n",
        "for resampler_name, resampler in resamplers.items():\n",
        "    print(f\"\\n--- Evaluating with {resampler_name} ---\")\n",
        "\n",
        "    # Define pipeline for resampling and scaling\n",
        "    pipeline = Pipeline([\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('resampler', resampler),\n",
        "        ('classifier', voting_clf)\n",
        "    ])\n",
        "\n",
        "    # Train and evaluate using cross-validation\n",
        "    scores = cross_val_score(pipeline, X2_train, y2_train, cv=5, scoring=make_scorer(fbeta_score, beta=1))\n",
        "    print(f\"Cross-validated F1 scores with {resampler_name}: {scores}\")\n",
        "    print(f\"Average F1 score with {resampler_name}: {np.mean(scores)}\")\n",
        "\n",
        "    # Final evaluation on the test set\n",
        "    print(f\"Evaluation with {resampler_name} on the test set:\")\n",
        "    evaluate_model(pipeline, X2_train, y2_train, X2_test, y2_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4H0pPBYrWbJ"
      },
      "source": [
        "#### Data - RandomOverSampler\n",
        "\n",
        "\n",
        "|Data|Model||\n",
        "|------|---|---|\n",
        "|RUS (RandomUnderSampler)|RandomForestClassifier|\n",
        "| |XGBClassifier|\n",
        "| |SGDClassifier|\n",
        "| |SVC|\n",
        "| |LGBMClassifier|\n",
        "| |DecisionTreeClassifier|\n",
        "\n",
        "\n",
        "Techniques used in here:\n",
        "1. RandomForestClassifier / XGBClassifier / SGDClassifier / SVC / LGBMClassifier/ DecisionTreeClassifier\n",
        "2. SMOTE\n",
        "3. SMOTE-Tomek\n",
        "4. SMOTEEN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQhqXPLNHC9p"
      },
      "source": [
        "#### Efficient Code for RandOverSampler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Ux2VMRSG2iU",
        "outputId": "18bb2629-0c61-4342-bec2-1a2eaff6f7e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RandomOverSampler - Class Distribution After Resampling:\n",
            "y\n",
            "1    25980\n",
            "0    25980\n",
            "Name: count, dtype: int64\n",
            "\n",
            "RandomOverSampler with RandomForestClassifier - Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.98      0.96     11124\n",
            "           1       0.50      0.28      0.36       876\n",
            "\n",
            "    accuracy                           0.93     12000\n",
            "   macro avg       0.72      0.63      0.66     12000\n",
            "weighted avg       0.91      0.93      0.92     12000\n",
            "\n",
            "RandomOverSampler with RandomForestClassifier - F0.5 Score: 0.43235704323570434\n",
            "RandomOverSampler with RandomForestClassifier - F2 Score: 0.3098450774612694\n",
            "\n",
            "RandomOverSampler - Class Distribution After Resampling:\n",
            "y\n",
            "1    25980\n",
            "0    25980\n",
            "Name: count, dtype: int64\n",
            "\n",
            "RandomOverSampler with XGBClassifier - Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.91      0.94     11124\n",
            "           1       0.36      0.63      0.46       876\n",
            "\n",
            "    accuracy                           0.89     12000\n",
            "   macro avg       0.66      0.77      0.70     12000\n",
            "weighted avg       0.92      0.89      0.90     12000\n",
            "\n",
            "RandomOverSampler with XGBClassifier - F0.5 Score: 0.3920034149117814\n",
            "RandomOverSampler with XGBClassifier - F2 Score: 0.5464101547005157\n",
            "\n",
            "RandomOverSampler - Class Distribution After Resampling:\n",
            "y\n",
            "1    25980\n",
            "0    25980\n",
            "Name: count, dtype: int64\n",
            "\n",
            "RandomOverSampler with SGDClassifier - Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.85      0.90     11124\n",
            "           1       0.23      0.56      0.33       876\n",
            "\n",
            "    accuracy                           0.83     12000\n",
            "   macro avg       0.60      0.71      0.62     12000\n",
            "weighted avg       0.91      0.83      0.86     12000\n",
            "\n",
            "RandomOverSampler with SGDClassifier - F0.5 Score: 0.26482595616673826\n",
            "RandomOverSampler with SGDClassifier - F2 Score: 0.43923734853884533\n",
            "\n",
            "RandomOverSampler - Class Distribution After Resampling:\n",
            "y\n",
            "1    25980\n",
            "0    25980\n",
            "Name: count, dtype: int64\n",
            "\n",
            "RandomOverSampler with SVC - Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.88      0.92     11124\n",
            "           1       0.27      0.58      0.37       876\n",
            "\n",
            "    accuracy                           0.85     12000\n",
            "   macro avg       0.62      0.73      0.64     12000\n",
            "weighted avg       0.91      0.85      0.88     12000\n",
            "\n",
            "RandomOverSampler with SVC - F0.5 Score: 0.3020292590844738\n",
            "RandomOverSampler with SVC - F2 Score: 0.47372316802368614\n",
            "\n",
            "RandomOverSampler - Class Distribution After Resampling:\n",
            "y\n",
            "1    25980\n",
            "0    25980\n",
            "Name: count, dtype: int64\n",
            "\n",
            "[LightGBM] [Info] Number of positive: 25980, number of negative: 25980\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003545 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 684\n",
            "[LightGBM] [Info] Number of data points in the train set: 51960, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "RandomOverSampler with LGBMClassifier - Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.87      0.92     11124\n",
            "           1       0.32      0.76      0.45       876\n",
            "\n",
            "    accuracy                           0.86     12000\n",
            "   macro avg       0.65      0.82      0.68     12000\n",
            "weighted avg       0.93      0.86      0.89     12000\n",
            "\n",
            "RandomOverSampler with LGBMClassifier - F0.5 Score: 0.35844797936371453\n",
            "RandomOverSampler with LGBMClassifier - F2 Score: 0.5943682053109962\n",
            "\n",
            "RandomOverSampler - Class Distribution After Resampling:\n",
            "y\n",
            "1    25980\n",
            "0    25980\n",
            "Name: count, dtype: int64\n",
            "\n",
            "RandomOverSampler with DecisionTreeClassifier - Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.95      0.95     11124\n",
            "           1       0.32      0.30      0.31       876\n",
            "\n",
            "    accuracy                           0.90     12000\n",
            "   macro avg       0.63      0.63      0.63     12000\n",
            "weighted avg       0.90      0.90      0.90     12000\n",
            "\n",
            "RandomOverSampler with DecisionTreeClassifier - F0.5 Score: 0.3145853193517636\n",
            "RandomOverSampler with DecisionTreeClassifier - F2 Score: 0.30456852791878175\n",
            "\n",
            "RandomOverSampler - Class Distribution After Resampling:\n",
            "y\n",
            "1    25980\n",
            "0    25980\n",
            "Name: count, dtype: int64\n",
            "\n",
            "RandomOverSampler with Perceptron - Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.16      0.28     11124\n",
            "           1       0.08      0.94      0.15       876\n",
            "\n",
            "    accuracy                           0.22     12000\n",
            "   macro avg       0.53      0.55      0.21     12000\n",
            "weighted avg       0.91      0.22      0.27     12000\n",
            "\n",
            "RandomOverSampler with Perceptron - F0.5 Score: 0.0990802272946162\n",
            "RandomOverSampler with Perceptron - F2 Score: 0.30106818846941763\n",
            "\n",
            "SMOTE - Class Distribution After Resampling:\n",
            "y\n",
            "1    25980\n",
            "0    25980\n",
            "Name: count, dtype: int64\n",
            "\n",
            "SMOTE with RandomForestClassifier - Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.94      0.94     11124\n",
            "           1       0.34      0.43      0.38       876\n",
            "\n",
            "    accuracy                           0.90     12000\n",
            "   macro avg       0.65      0.68      0.66     12000\n",
            "weighted avg       0.91      0.90      0.90     12000\n",
            "\n",
            "SMOTE with RandomForestClassifier - F0.5 Score: 0.35795454545454547\n",
            "SMOTE with RandomForestClassifier - F2 Score: 0.41042345276872966\n",
            "\n",
            "SMOTE - Class Distribution After Resampling:\n",
            "y\n",
            "1    25980\n",
            "0    25980\n",
            "Name: count, dtype: int64\n",
            "\n",
            "SMOTE with XGBClassifier - Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.93      0.94     11124\n",
            "           1       0.35      0.48      0.41       876\n",
            "\n",
            "    accuracy                           0.90     12000\n",
            "   macro avg       0.66      0.71      0.68     12000\n",
            "weighted avg       0.91      0.90      0.90     12000\n",
            "\n",
            "SMOTE with XGBClassifier - F0.5 Score: 0.3736749116607774\n",
            "SMOTE with XGBClassifier - F2 Score: 0.45\n",
            "\n",
            "SMOTE - Class Distribution After Resampling:\n",
            "y\n",
            "1    25980\n",
            "0    25980\n",
            "Name: count, dtype: int64\n",
            "\n",
            "SMOTE with SGDClassifier - Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.65      0.78     11124\n",
            "           1       0.15      0.81      0.26       876\n",
            "\n",
            "    accuracy                           0.66     12000\n",
            "   macro avg       0.57      0.73      0.52     12000\n",
            "weighted avg       0.92      0.66      0.74     12000\n",
            "\n",
            "SMOTE with SGDClassifier - F0.5 Score: 0.1827080770807708\n",
            "SMOTE with SGDClassifier - F2 Score: 0.43672669361754257\n",
            "\n",
            "SMOTE - Class Distribution After Resampling:\n",
            "y\n",
            "1    25980\n",
            "0    25980\n",
            "Name: count, dtype: int64\n",
            "\n",
            "SMOTE with SVC - Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.88      0.92     11124\n",
            "           1       0.27      0.58      0.37       876\n",
            "\n",
            "    accuracy                           0.86     12000\n",
            "   macro avg       0.62      0.73      0.64     12000\n",
            "weighted avg       0.91      0.86      0.88     12000\n",
            "\n",
            "SMOTE with SVC - F0.5 Score: 0.30371605526441164\n",
            "SMOTE with SVC - F2 Score: 0.4736255572065379\n",
            "\n",
            "SMOTE - Class Distribution After Resampling:\n",
            "y\n",
            "1    25980\n",
            "0    25980\n",
            "Name: count, dtype: int64\n",
            "\n",
            "[LightGBM] [Info] Number of positive: 25980, number of negative: 25980\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004826 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 687\n",
            "[LightGBM] [Info] Number of data points in the train set: 51960, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "SMOTE with LGBMClassifier - Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.91      0.93     11124\n",
            "           1       0.32      0.55      0.40       876\n",
            "\n",
            "    accuracy                           0.88     12000\n",
            "   macro avg       0.64      0.73      0.67     12000\n",
            "weighted avg       0.92      0.88      0.89     12000\n",
            "\n",
            "SMOTE with LGBMClassifier - F0.5 Score: 0.3460207612456747\n",
            "SMOTE with LGBMClassifier - F2 Score: 0.4781829049611476\n",
            "\n",
            "SMOTE - Class Distribution After Resampling:\n",
            "y\n",
            "1    25980\n",
            "0    25980\n",
            "Name: count, dtype: int64\n",
            "\n",
            "SMOTE with DecisionTreeClassifier - Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.88      0.91     11124\n",
            "           1       0.21      0.41      0.28       876\n",
            "\n",
            "    accuracy                           0.85     12000\n",
            "   macro avg       0.58      0.64      0.60     12000\n",
            "weighted avg       0.90      0.85      0.87     12000\n",
            "\n",
            "SMOTE with DecisionTreeClassifier - F0.5 Score: 0.23516163222045575\n",
            "SMOTE with DecisionTreeClassifier - F2 Score: 0.3431941221964424\n",
            "\n",
            "SMOTE - Class Distribution After Resampling:\n",
            "y\n",
            "1    25980\n",
            "0    25980\n",
            "Name: count, dtype: int64\n",
            "\n",
            "SMOTE with Perceptron - Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.27      0.42     11124\n",
            "           1       0.09      0.92      0.16       876\n",
            "\n",
            "    accuracy                           0.32     12000\n",
            "   macro avg       0.53      0.59      0.29     12000\n",
            "weighted avg       0.91      0.32      0.40     12000\n",
            "\n",
            "SMOTE with Perceptron - F0.5 Score: 0.11003280481137233\n",
            "SMOTE with Perceptron - F2 Score: 0.3238133547868061\n",
            "\n",
            "SMOTE-Tomek - Class Distribution After Resampling:\n",
            "y\n",
            "1    25369\n",
            "0    25369\n",
            "Name: count, dtype: int64\n",
            "\n",
            "SMOTE-Tomek with RandomForestClassifier - Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.93      0.94     11124\n",
            "           1       0.35      0.44      0.39       876\n",
            "\n",
            "    accuracy                           0.90     12000\n",
            "   macro avg       0.65      0.69      0.67     12000\n",
            "weighted avg       0.91      0.90      0.90     12000\n",
            "\n",
            "SMOTE-Tomek with RandomForestClassifier - F0.5 Score: 0.36140089418777943\n",
            "SMOTE-Tomek with RandomForestClassifier - F2 Score: 0.4192781499891939\n",
            "\n",
            "SMOTE-Tomek - Class Distribution After Resampling:\n",
            "y\n",
            "1    25369\n",
            "0    25369\n",
            "Name: count, dtype: int64\n",
            "\n",
            "SMOTE-Tomek with XGBClassifier - Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.93      0.94     11124\n",
            "           1       0.35      0.48      0.41       876\n",
            "\n",
            "    accuracy                           0.90     12000\n",
            "   macro avg       0.66      0.70      0.68     12000\n",
            "weighted avg       0.91      0.90      0.91     12000\n",
            "\n",
            "SMOTE-Tomek with XGBClassifier - F0.5 Score: 0.37392395982783355\n",
            "SMOTE-Tomek with XGBClassifier - F2 Score: 0.44560803590510795\n",
            "\n",
            "SMOTE-Tomek - Class Distribution After Resampling:\n",
            "y\n",
            "1    25369\n",
            "0    25369\n",
            "Name: count, dtype: int64\n",
            "\n",
            "SMOTE-Tomek with SGDClassifier - Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.90      0.93     11124\n",
            "           1       0.29      0.50      0.36       876\n",
            "\n",
            "    accuracy                           0.87     12000\n",
            "   macro avg       0.62      0.70      0.65     12000\n",
            "weighted avg       0.91      0.87      0.89     12000\n",
            "\n",
            "SMOTE-Tomek with SGDClassifier - F0.5 Score: 0.31214121699196323\n",
            "SMOTE-Tomek with SGDClassifier - F2 Score: 0.4326636164710563\n",
            "\n",
            "SMOTE-Tomek - Class Distribution After Resampling:\n",
            "y\n",
            "1    25369\n",
            "0    25369\n",
            "Name: count, dtype: int64\n",
            "\n",
            "SMOTE-Tomek with SVC - Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.88      0.92     11124\n",
            "           1       0.27      0.58      0.37       876\n",
            "\n",
            "    accuracy                           0.86     12000\n",
            "   macro avg       0.62      0.73      0.64     12000\n",
            "weighted avg       0.91      0.86      0.88     12000\n",
            "\n",
            "SMOTE-Tomek with SVC - F0.5 Score: 0.30416666666666664\n",
            "SMOTE-Tomek with SVC - F2 Score: 0.4744661095636026\n",
            "\n",
            "SMOTE-Tomek - Class Distribution After Resampling:\n",
            "y\n",
            "1    25369\n",
            "0    25369\n",
            "Name: count, dtype: int64\n",
            "\n",
            "[LightGBM] [Info] Number of positive: 25369, number of negative: 25369\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004408 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 687\n",
            "[LightGBM] [Info] Number of data points in the train set: 50738, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "SMOTE-Tomek with LGBMClassifier - Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.91      0.93     11124\n",
            "           1       0.32      0.55      0.40       876\n",
            "\n",
            "    accuracy                           0.88     12000\n",
            "   macro avg       0.64      0.73      0.67     12000\n",
            "weighted avg       0.92      0.88      0.90     12000\n",
            "\n",
            "SMOTE-Tomek with LGBMClassifier - F0.5 Score: 0.3484673221515327\n",
            "SMOTE-Tomek with LGBMClassifier - F2 Score: 0.4806541683286797\n",
            "\n",
            "SMOTE-Tomek - Class Distribution After Resampling:\n",
            "y\n",
            "1    25369\n",
            "0    25369\n",
            "Name: count, dtype: int64\n",
            "\n",
            "SMOTE-Tomek with DecisionTreeClassifier - Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.88      0.92     11124\n",
            "           1       0.22      0.44      0.30       876\n",
            "\n",
            "    accuracy                           0.85     12000\n",
            "   macro avg       0.59      0.66      0.61     12000\n",
            "weighted avg       0.90      0.85      0.87     12000\n",
            "\n",
            "SMOTE-Tomek with DecisionTreeClassifier - F0.5 Score: 0.24779449922158797\n",
            "SMOTE-Tomek with DecisionTreeClassifier - F2 Score: 0.3664620107444359\n",
            "\n",
            "SMOTE-Tomek - Class Distribution After Resampling:\n",
            "y\n",
            "1    25369\n",
            "0    25369\n",
            "Name: count, dtype: int64\n",
            "\n",
            "SMOTE-Tomek with Perceptron - Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.23      0.37     11124\n",
            "           1       0.09      0.93      0.16       876\n",
            "\n",
            "    accuracy                           0.28     12000\n",
            "   macro avg       0.53      0.58      0.27     12000\n",
            "weighted avg       0.91      0.28      0.36     12000\n",
            "\n",
            "SMOTE-Tomek with Perceptron - F0.5 Score: 0.10594543940024989\n",
            "SMOTE-Tomek with Perceptron - F2 Score: 0.3157731398867251\n",
            "\n",
            "SMOTE-ENN - Class Distribution After Resampling:\n",
            "y\n",
            "1    22497\n",
            "0    17384\n",
            "Name: count, dtype: int64\n",
            "\n",
            "SMOTE-ENN with RandomForestClassifier - Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.89      0.93     11124\n",
            "           1       0.31      0.64      0.42       876\n",
            "\n",
            "    accuracy                           0.87     12000\n",
            "   macro avg       0.64      0.76      0.67     12000\n",
            "weighted avg       0.92      0.87      0.89     12000\n",
            "\n",
            "SMOTE-ENN with RandomForestClassifier - F0.5 Score: 0.34516765285996054\n",
            "SMOTE-ENN with RandomForestClassifier - F2 Score: 0.5270092226613966\n",
            "\n",
            "SMOTE-ENN - Class Distribution After Resampling:\n",
            "y\n",
            "1    22497\n",
            "0    17384\n",
            "Name: count, dtype: int64\n",
            "\n",
            "SMOTE-ENN with XGBClassifier - Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.89      0.93     11124\n",
            "           1       0.31      0.63      0.41       876\n",
            "\n",
            "    accuracy                           0.87     12000\n",
            "   macro avg       0.64      0.76      0.67     12000\n",
            "weighted avg       0.92      0.87      0.89     12000\n",
            "\n",
            "SMOTE-ENN with XGBClassifier - F0.5 Score: 0.3416912487708948\n",
            "SMOTE-ENN with XGBClassifier - F2 Score: 0.5226546343297612\n",
            "\n",
            "SMOTE-ENN - Class Distribution After Resampling:\n",
            "y\n",
            "1    22497\n",
            "0    17384\n",
            "Name: count, dtype: int64\n",
            "\n",
            "SMOTE-ENN with SGDClassifier - Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.86      0.90     11124\n",
            "           1       0.19      0.42      0.26       876\n",
            "\n",
            "    accuracy                           0.83     12000\n",
            "   macro avg       0.57      0.64      0.58     12000\n",
            "weighted avg       0.89      0.83      0.85     12000\n",
            "\n",
            "SMOTE-ENN with SGDClassifier - F0.5 Score: 0.21390682656826568\n",
            "SMOTE-ENN with SGDClassifier - F2 Score: 0.34017971758664955\n",
            "\n",
            "SMOTE-ENN - Class Distribution After Resampling:\n",
            "y\n",
            "1    22497\n",
            "0    17384\n",
            "Name: count, dtype: int64\n",
            "\n",
            "SMOTE-ENN with SVC - Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.83      0.89     11124\n",
            "           1       0.23      0.64      0.33       876\n",
            "\n",
            "    accuracy                           0.81     12000\n",
            "   macro avg       0.60      0.73      0.61     12000\n",
            "weighted avg       0.91      0.81      0.85     12000\n",
            "\n",
            "SMOTE-ENN with SVC - F0.5 Score: 0.2585406609728927\n",
            "SMOTE-ENN with SVC - F2 Score: 0.46587487453997994\n",
            "\n",
            "SMOTE-ENN - Class Distribution After Resampling:\n",
            "y\n",
            "1    22497\n",
            "0    17384\n",
            "Name: count, dtype: int64\n",
            "\n",
            "[LightGBM] [Info] Number of positive: 22497, number of negative: 17384\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003572 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 684\n",
            "[LightGBM] [Info] Number of data points in the train set: 39881, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.564103 -> initscore=0.257832\n",
            "[LightGBM] [Info] Start training from score 0.257832\n",
            "SMOTE-ENN with LGBMClassifier - Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.87      0.92     11124\n",
            "           1       0.29      0.68      0.41       876\n",
            "\n",
            "    accuracy                           0.86     12000\n",
            "   macro avg       0.63      0.78      0.66     12000\n",
            "weighted avg       0.92      0.86      0.88     12000\n",
            "\n",
            "SMOTE-ENN with LGBMClassifier - F0.5 Score: 0.32981530343007914\n",
            "SMOTE-ENN with LGBMClassifier - F2 Score: 0.5396654074473827\n",
            "\n",
            "SMOTE-ENN - Class Distribution After Resampling:\n",
            "y\n",
            "1    22497\n",
            "0    17384\n",
            "Name: count, dtype: int64\n",
            "\n",
            "SMOTE-ENN with DecisionTreeClassifier - Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.85      0.90     11124\n",
            "           1       0.23      0.60      0.34       876\n",
            "\n",
            "    accuracy                           0.83     12000\n",
            "   macro avg       0.60      0.72      0.62     12000\n",
            "weighted avg       0.91      0.83      0.86     12000\n",
            "\n",
            "SMOTE-ENN with DecisionTreeClassifier - F0.5 Score: 0.26629327902240324\n",
            "SMOTE-ENN with DecisionTreeClassifier - F2 Score: 0.45557491289198604\n",
            "\n",
            "SMOTE-ENN - Class Distribution After Resampling:\n",
            "y\n",
            "1    22497\n",
            "0    17384\n",
            "Name: count, dtype: int64\n",
            "\n",
            "SMOTE-ENN with Perceptron - Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.91      0.93     11124\n",
            "           1       0.22      0.32      0.26       876\n",
            "\n",
            "    accuracy                           0.87     12000\n",
            "   macro avg       0.58      0.61      0.59     12000\n",
            "weighted avg       0.89      0.87      0.88     12000\n",
            "\n",
            "SMOTE-ENN with Perceptron - F0.5 Score: 0.23043766578249336\n",
            "SMOTE-ENN with Perceptron - F2 Score: 0.29000625912789485\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Define a function to train and evaluate different models with different samplers\n",
        "def train_and_evaluate_ro_models(X_train, y_train, X_test, y_test, sampler, sampler_name, classifier, classifier_name):\n",
        "    # Resample the training data\n",
        "    X_resampled, y_resampled = sampler.fit_resample(X_train, y_train)\n",
        "    print(f\"{sampler_name} - Class Distribution After Resampling:\\n{y_resampled.value_counts()}\\n\")\n",
        "\n",
        "    # Train the model\n",
        "    model = classifier\n",
        "    model.fit(X_resampled, y_resampled)\n",
        "\n",
        "    # Predict on the test set\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Print evaluation metrics\n",
        "    print(f\"{sampler_name} with {classifier_name} - Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "    fhalf_score = fbeta_score(y_test, y_pred, beta=0.5)\n",
        "    f2_score = fbeta_score(y_test, y_pred, beta=2)\n",
        "    print(f\"{sampler_name} with {classifier_name} - F0.5 Score: {fhalf_score}\")\n",
        "    print(f\"{sampler_name} with {classifier_name} - F2 Score: {f2_score}\\n\")\n",
        "\n",
        "# List of classifiers to test\n",
        "classifiers = [\n",
        "    (RandomForestClassifier(random_state=seed), \"RandomForestClassifier\"),\n",
        "    (XGBClassifier(random_state=seed, use_label_encoder=False, eval_metric='mlogloss'), \"XGBClassifier\"),\n",
        "    (SGDClassifier(random_state=seed), \"SGDClassifier\"),\n",
        "    (SVC(random_state=seed), \"SVC\"),\n",
        "    (LGBMClassifier(random_state=seed), \"LGBMClassifier\"),\n",
        "    (DecisionTreeClassifier(random_state=seed), \"DecisionTreeClassifier\"),\n",
        "    (Perceptron(random_state=seed), \"Perceptron\")\n",
        "]\n",
        "\n",
        "# List of resampling techniques to apply\n",
        "samplers = [\n",
        "    (RandomOverSampler(sampling_strategy='minority', random_state=seed), \"RandomOverSampler\"),\n",
        "    (SMOTE(sampling_strategy='minority', random_state=seed), \"SMOTE\"),\n",
        "    (SMOTETomek(sampling_strategy='minority', random_state=seed), \"SMOTE-Tomek\"),\n",
        "    (SMOTEENN(sampling_strategy='minority', random_state=seed), \"SMOTE-ENN\")\n",
        "]\n",
        "\n",
        "# Run the training and evaluation for each combination of sampler and classifier\n",
        "for sampler, sampler_name in samplers:\n",
        "    for classifier, classifier_name in classifiers:\n",
        "        train_and_evaluate_ro_models(X2_train, y2_train, X2_test, y2_test, sampler, sampler_name, classifier, classifier_name)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qnbpO769k1pm"
      },
      "source": [
        "##### RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "FndxdgZDk6qs",
        "outputId": "9e5baf56-7496-43c6-f0a3-e19b02094d04"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "y\n",
            "0    2020\n",
            "1    2020\n",
            "Name: count, dtype: int64\n",
            "RandomForestClassifier Applied with RandomUnderSampler: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.83      0.90     11124\n",
            "           1       0.27      0.81      0.40       876\n",
            "\n",
            "    accuracy                           0.83     12000\n",
            "   macro avg       0.63      0.82      0.65     12000\n",
            "weighted avg       0.93      0.83      0.86     12000\n",
            "\n",
            "F0.5 Score: 0.3111777150916784\n",
            "F2 Score: 0.5767031530795622\n",
            "y\n",
            "1    25980\n",
            "0    25980\n",
            "Name: count, dtype: int64\n",
            "RFC-SMOTE Applied: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.94      0.94     11124\n",
            "           1       0.34      0.43      0.38       876\n",
            "\n",
            "    accuracy                           0.90     12000\n",
            "   macro avg       0.65      0.68      0.66     12000\n",
            "weighted avg       0.91      0.90      0.90     12000\n",
            "\n",
            "F0.5 Score: 0.11003280481137233\n",
            "F2 Score: 0.3238133547868061\n",
            "y\n",
            "1    25369\n",
            "0    25369\n",
            "Name: count, dtype: int64\n",
            "RFC-SMOTE TOMEK Applied: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.93      0.94     11124\n",
            "           1       0.35      0.44      0.39       876\n",
            "\n",
            "    accuracy                           0.90     12000\n",
            "   macro avg       0.65      0.69      0.67     12000\n",
            "weighted avg       0.91      0.90      0.90     12000\n",
            "\n",
            "F0.5 Score: 0.10594543940024989\n",
            "F2 Score: 0.3157731398867251\n",
            "y\n",
            "1    22497\n",
            "0    17384\n",
            "Name: count, dtype: int64\n",
            "RFC-SMOTEEN Applied: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.89      0.93     11124\n",
            "           1       0.31      0.64      0.42       876\n",
            "\n",
            "    accuracy                           0.87     12000\n",
            "   macro avg       0.64      0.76      0.67     12000\n",
            "weighted avg       0.92      0.87      0.89     12000\n",
            "\n",
            "F0.5 Score: 0.23043766578249336\n",
            "F2 Score: 0.29000625912789485\n"
          ]
        }
      ],
      "source": [
        "# 1. Apply RandomUnderSampler\n",
        "ros = RandomOverSampler(sampling_strategy='minority', random_state=seed)\n",
        "X2_train_ros, y2_train_ros = rus.fit_resample(X2_train, y2_train)\n",
        "print(y2_train_ros.value_counts())\n",
        "\n",
        "\n",
        "# Initiate RandomForestClassifier\n",
        "rfc_ros = RandomForestClassifier(random_state=seed)\n",
        "rfc_ros.fit(X2_train_ros, y2_train_ros)\n",
        "y2_pred = rfc_ros.predict(X2_test)\n",
        "print(f\"RandomForestClassifier Applied with RandomUnderSampler: \\n\", classification_report(y2_test, y2_pred))\n",
        "# the result is skewed, since the data is imbalanced\n",
        "fhalf_score = fbeta_score(y2_test, y2_pred, beta=0.5)\n",
        "print(f\"F0.5 Score: {fhalf_score}\")\n",
        "f2_score = fbeta_score(y2_test, y2_pred, beta=2)\n",
        "print(f\"F2 Score: {f2_score}\")\n",
        "\n",
        "\n",
        "# 2. Apply SMOTE (Synthetic Minotiry Oversampling Technique)\n",
        "sm = SMOTE(sampling_strategy = 'minority', random_state=seed)\n",
        "X2_train_sm, y2_train_sm = sm.fit_resample(X2_train, y2_train)\n",
        "print(y2_train_sm.value_counts())\n",
        "# Initiating RandomForestClassifier\n",
        "rfc_sm = RandomForestClassifier(random_state=seed)\n",
        "rfc_sm.fit(X2_train_sm, y2_train_sm)\n",
        "y2_pred_sm = rfc_sm.predict(X2_test)\n",
        "print(f\"RFC-SMOTE Applied: \\n\", classification_report(y2_test, y2_pred_sm))\n",
        "fhalf_score = fbeta_score(y2_test, y2_pred_sm, beta=0.5)\n",
        "print(f\"F0.5 Score: {fhalf_score_sm}\")\n",
        "f2_score = fbeta_score(y2_test, y2_pred_sm, beta=2)\n",
        "print(f\"F2 Score: {f2_score_sm}\")\n",
        "\n",
        "\n",
        "# 3. Apply SMOTE-TOMEK\n",
        "smt = SMOTETomek(sampling_strategy = 'minority', random_state=seed)\n",
        "X2_train_smt, y2_train_smt = smt.fit_resample(X2_train, y2_train)\n",
        "print(y2_train_smt.value_counts())\n",
        "# Initiating RandomForestClassifier\n",
        "rfc_smt = RandomForestClassifier(random_state=seed)\n",
        "rfc_smt.fit(X2_train_smt, y2_train_smt)\n",
        "y2_pred_smt = rfc_smt.predict(X2_test)\n",
        "print(f\"RFC-SMOTE TOMEK Applied: \\n\", classification_report(y2_test, y2_pred_smt))\n",
        "fhalf_score = fbeta_score(y2_test, y2_pred_smt, beta=0.5)\n",
        "print(f\"F0.5 Score: {fhalf_score_smt}\")\n",
        "f2_score = fbeta_score(y2_test, y2_pred_smt, beta=2)\n",
        "print(f\"F2 Score: {f2_score_smt}\")\n",
        "\n",
        "\n",
        "# 4. Apply SMOTEEN to balance the classes\n",
        "smn = SMOTEENN(sampling_strategy = 'minority', random_state=seed)\n",
        "X2_train_smn, y2_train_smn = smn.fit_resample(X2_train, y2_train)\n",
        "print(y2_train_smn.value_counts())\n",
        "# Initiating RandomForestClassifier\n",
        "rfc_smn = RandomForestClassifier(random_state=seed)\n",
        "rfc_smn.fit(X2_train_smn, y2_train_smn)\n",
        "y2_pred_smn = rfc_smn.predict(X2_test)\n",
        "print(f\"RFC-SMOTEEN Applied: \\n\", classification_report(y2_test, y2_pred_smn))\n",
        "fhalf_score = fbeta_score(y2_test, y2_pred_smn, beta=0.5)\n",
        "print(f\"F0.5 Score: {fhalf_score_smn}\")\n",
        "f2_score = fbeta_score(y2_test, y2_pred_smn, beta=2)\n",
        "print(f\"F2 Score: {f2_score_smn}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxU4dRvKk5Zy"
      },
      "source": [
        "##### XGBClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "nDhHtsLPk9U1",
        "outputId": "2b2f9ac2-2199-4475-d93d-dcc298c295f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "y\n",
            "1    25980\n",
            "0    25980\n",
            "Name: count, dtype: int64\n",
            "XGBClassifier Applied with RandomUnderSampler: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.91      0.94     11124\n",
            "           1       0.36      0.63      0.46       876\n",
            "\n",
            "    accuracy                           0.89     12000\n",
            "   macro avg       0.66      0.77      0.70     12000\n",
            "weighted avg       0.92      0.89      0.90     12000\n",
            "\n",
            "F0.5 Score: 0.3920034149117814\n",
            "F2 Score: 0.5464101547005157\n",
            "y\n",
            "1    25980\n",
            "0    25980\n",
            "Name: count, dtype: int64\n",
            "XGB-SMOTE Applied: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.93      0.94     11124\n",
            "           1       0.35      0.48      0.41       876\n",
            "\n",
            "    accuracy                           0.90     12000\n",
            "   macro avg       0.66      0.71      0.68     12000\n",
            "weighted avg       0.91      0.90      0.90     12000\n",
            "\n",
            "F0.5 Score: 0.11003280481137233\n",
            "F2 Score: 0.3238133547868061\n",
            "y\n",
            "1    25369\n",
            "0    25369\n",
            "Name: count, dtype: int64\n",
            "RFC-SMOTE TOMEK Applied: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.93      0.94     11124\n",
            "           1       0.35      0.48      0.41       876\n",
            "\n",
            "    accuracy                           0.90     12000\n",
            "   macro avg       0.66      0.70      0.68     12000\n",
            "weighted avg       0.91      0.90      0.91     12000\n",
            "\n",
            "F0.5 Score: 0.10594543940024989\n",
            "F2 Score: 0.3157731398867251\n",
            "y\n",
            "1    22497\n",
            "0    17384\n",
            "Name: count, dtype: int64\n",
            "RFC-SMOTEEN Applied: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.89      0.93     11124\n",
            "           1       0.31      0.63      0.41       876\n",
            "\n",
            "    accuracy                           0.87     12000\n",
            "   macro avg       0.64      0.76      0.67     12000\n",
            "weighted avg       0.92      0.87      0.89     12000\n",
            "\n",
            "F0.5 Score: 0.23043766578249336\n",
            "F2 Score: 0.29000625912789485\n"
          ]
        }
      ],
      "source": [
        "# 1. Apply RandomUnderSampler\n",
        "ros = RandomOverSampler(sampling_strategy='minority', random_state=seed)\n",
        "X2_train_ros, y2_train_ros = ros.fit_resample(X2_train, y2_train)\n",
        "print(y2_train_ros.value_counts())\n",
        "\n",
        "# Initiate XGBClassifier\n",
        "xgb_ros = XGBClassifier(random_state=seed)\n",
        "xgb_ros.fit(X2_train_ros, y2_train_ros)\n",
        "y2_pred = xgb_ros.predict(X2_test)\n",
        "print(f\"XGBClassifier Applied with RandomUnderSampler: \\n\", classification_report(y2_test, y2_pred))\n",
        "# the result is skewed, since the data is imbalanced\n",
        "fhalf_score = fbeta_score(y2_test, y2_pred, beta=0.5)\n",
        "print(f\"F0.5 Score: {fhalf_score}\")\n",
        "f2_score = fbeta_score(y2_test, y2_pred, beta=2)\n",
        "print(f\"F2 Score: {f2_score}\")\n",
        "\n",
        "\n",
        "# 2. Apply SMOTE (Synthetic Minotiry Oversampling Technique)\n",
        "sm = SMOTE(sampling_strategy = 'minority', random_state=seed)\n",
        "X2_train_sm, y2_train_sm = sm.fit_resample(X2_train, y2_train)\n",
        "print(y2_train_sm.value_counts())\n",
        "# Initiating XGBClassifier\n",
        "xgb_sm = XGBClassifier(random_state=seed)\n",
        "xgb_sm.fit(X2_train_sm, y2_train_sm)\n",
        "y2_pred_sm = xgb_sm.predict(X2_test)\n",
        "print(f\"XGB-SMOTE Applied: \\n\", classification_report(y2_test, y2_pred_sm))\n",
        "fhalf_score = fbeta_score(y2_test, y2_pred_sm, beta=0.5)\n",
        "print(f\"F0.5 Score: {fhalf_score_sm}\")\n",
        "f2_score = fbeta_score(y2_test, y2_pred_sm, beta=2)\n",
        "print(f\"F2 Score: {f2_score_sm}\")\n",
        "\n",
        "# 3. Apply SMOTE-TOMEK\n",
        "smt = SMOTETomek(sampling_strategy = 'minority', random_state=seed)\n",
        "X2_train_smt, y1_train_smt = smt.fit_resample(X2_train, y2_train)\n",
        "print(y2_train_smt.value_counts())\n",
        "# Initiating XGBClassifier\n",
        "xgb_smt = XGBClassifier(random_state=seed)\n",
        "xgb_smt.fit(X2_train_smt, y2_train_smt)\n",
        "y2_pred_smt = xgb_smt.predict(X2_test)\n",
        "print(f\"RFC-SMOTE TOMEK Applied: \\n\", classification_report(y2_test, y2_pred_smt))\n",
        "fhalf_score = fbeta_score(y2_test, y2_pred_smt, beta=0.5)\n",
        "print(f\"F0.5 Score: {fhalf_score_smt}\")\n",
        "f2_score = fbeta_score(y2_test, y2_pred_smt, beta=2)\n",
        "print(f\"F2 Score: {f2_score_smt}\")\n",
        "\n",
        "\n",
        "# 4. Apply SMOTEEN to balance the classes\n",
        "smn = SMOTEENN(sampling_strategy = 'minority', random_state=seed)\n",
        "X2_train_smn, y2_train_smn = smn.fit_resample(X2_train, y2_train)\n",
        "print(y2_train_smn.value_counts())\n",
        "# Initiating RandomForestClassifier\n",
        "xgb_smn = XGBClassifier(random_state=seed)\n",
        "xgb_smn.fit(X2_train_smn, y2_train_smn)\n",
        "y2_pred_smn = xgb_smn.predict(X2_test)\n",
        "print(f\"RFC-SMOTEEN Applied: \\n\", classification_report(y2_test, y2_pred_smn))\n",
        "fhalf_score = fbeta_score(y2_test, y2_pred_smn, beta=0.5)\n",
        "print(f\"F0.5 Score: {fhalf_score_smn}\")\n",
        "f2_score = fbeta_score(y2_test, y2_pred_smn, beta=2)\n",
        "print(f\"F2 Score: {f2_score_smn}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qeemgpMik-P7"
      },
      "source": [
        "##### SGDClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "bOnuzhIelAUU",
        "outputId": "96daca1a-8b9c-445c-c24a-02ec2808bbe8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "y\n",
            "1    25980\n",
            "0    25980\n",
            "Name: count, dtype: int64\n",
            "SGDClassifier Applied with RandomOverSampler: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.85      0.90     11124\n",
            "           1       0.23      0.56      0.33       876\n",
            "\n",
            "    accuracy                           0.83     12000\n",
            "   macro avg       0.60      0.71      0.62     12000\n",
            "weighted avg       0.91      0.83      0.86     12000\n",
            "\n",
            "F0.5 Score: 0.26482595616673826\n",
            "F2 Score: 0.43923734853884533\n",
            "y\n",
            "1    25980\n",
            "0    25980\n",
            "Name: count, dtype: int64\n",
            "SGD-SMOTE Applied: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.65      0.78     11124\n",
            "           1       0.15      0.81      0.26       876\n",
            "\n",
            "    accuracy                           0.66     12000\n",
            "   macro avg       0.57      0.73      0.52     12000\n",
            "weighted avg       0.92      0.66      0.74     12000\n",
            "\n",
            "F0.5 Score: 0.11003280481137233\n",
            "F2 Score: 0.3238133547868061\n",
            "y\n",
            "1    25369\n",
            "0    25369\n",
            "Name: count, dtype: int64\n",
            "SGD-SMOTE TOMEK Applied: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.90      0.93     11124\n",
            "           1       0.29      0.50      0.36       876\n",
            "\n",
            "    accuracy                           0.87     12000\n",
            "   macro avg       0.62      0.70      0.65     12000\n",
            "weighted avg       0.91      0.87      0.89     12000\n",
            "\n",
            "F0.5 Score: 0.10594543940024989\n",
            "F2 Score: 0.3157731398867251\n",
            "y\n",
            "1    22497\n",
            "0    17384\n",
            "Name: count, dtype: int64\n",
            "SGD-SMOTEEN Applied: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.86      0.90     11124\n",
            "           1       0.19      0.42      0.26       876\n",
            "\n",
            "    accuracy                           0.83     12000\n",
            "   macro avg       0.57      0.64      0.58     12000\n",
            "weighted avg       0.89      0.83      0.85     12000\n",
            "\n",
            "F0.5 Score: 0.23043766578249336\n",
            "F2 Score: 0.29000625912789485\n"
          ]
        }
      ],
      "source": [
        "# 1. Apply RandomUnderSampler\n",
        "ros = RandomOverSampler(sampling_strategy='minority', random_state=seed)\n",
        "X2_train_ros, y2_train_ros = ros.fit_resample(X2_train, y2_train)\n",
        "print(y2_train_ros.value_counts())\n",
        "\n",
        "# Initiate SGDClassifier\n",
        "sgd_ros = SGDClassifier(random_state=seed)\n",
        "sgd_ros.fit(X2_train_ros, y2_train_ros)\n",
        "y2_pred = sgd_ros.predict(X2_test)\n",
        "print(f\"SGDClassifier Applied with RandomOverSampler: \\n\", classification_report(y2_test, y2_pred))\n",
        "# the result is skewed, since the data is imbalanced\n",
        "fhalf_score = fbeta_score(y2_test, y2_pred, beta=0.5)\n",
        "print(f\"F0.5 Score: {fhalf_score}\")\n",
        "f2_score = fbeta_score(y2_test, y2_pred, beta=2)\n",
        "print(f\"F2 Score: {f2_score}\")\n",
        "\n",
        "\n",
        "# 2. Apply SMOTE (Synthetic Minotiry Oversampling Technique)\n",
        "sm = SMOTE(sampling_strategy = 'minority', random_state=seed)\n",
        "X2_train_sm, y2_train_sm = sm.fit_resample(X2_train, y2_train)\n",
        "print(y2_train_sm.value_counts())\n",
        "# Initiating SGDClassifier\n",
        "sgd_sm = SGDClassifier(random_state=seed)\n",
        "sgd_sm.fit(X2_train_sm, y2_train_sm)\n",
        "y2_pred_sm = sgd_sm.predict(X2_test)\n",
        "print(f\"SGD-SMOTE Applied: \\n\", classification_report(y2_test, y2_pred_sm))\n",
        "fhalf_score = fbeta_score(y2_test, y2_pred_sm, beta=0.5)\n",
        "print(f\"F0.5 Score: {fhalf_score_sm}\")\n",
        "f2_score = fbeta_score(y2_test, y2_pred_sm, beta=2)\n",
        "print(f\"F2 Score: {f2_score_sm}\")\n",
        "\n",
        "\n",
        "# 3. Apply SMOTE-TOMEK\n",
        "smt = SMOTETomek(sampling_strategy = 'minority', random_state=seed)\n",
        "X2_train_smt, y2_train_smt = smt.fit_resample(X2_train, y2_train)\n",
        "print(y1_train_smt.value_counts())\n",
        "# Initiating SGDClassifier\n",
        "sgd_smt = SGDClassifier(random_state=seed)\n",
        "sgd_smt.fit(X2_train_smt, y2_train_smt)\n",
        "y2_pred_smt = sgd_smt.predict(X2_test)\n",
        "print(f\"SGD-SMOTE TOMEK Applied: \\n\", classification_report(y2_test, y2_pred_smt))\n",
        "fhalf_score = fbeta_score(y2_test, y2_pred_smt, beta=0.5)\n",
        "print(f\"F0.5 Score: {fhalf_score_smt}\")\n",
        "f2_score = fbeta_score(y2_test, y2_pred_smt, beta=2)\n",
        "print(f\"F2 Score: {f2_score_smt}\")\n",
        "\n",
        "\n",
        "# 4. Apply SMOTEEN to balance the classes\n",
        "smn = SMOTEENN(sampling_strategy = 'minority', random_state=seed)\n",
        "X2_train_smn, y2_train_smn = smn.fit_resample(X2_train, y2_train)\n",
        "print(y2_train_smn.value_counts())\n",
        "# Initiating SGDClassifier\n",
        "sgd_smn = SGDClassifier(random_state=seed)\n",
        "sgd_smn.fit(X2_train_smn, y2_train_smn)\n",
        "y2_pred_smn = sgd_smn.predict(X2_test)\n",
        "print(f\"SGD-SMOTEEN Applied: \\n\", classification_report(y2_test, y2_pred_smn))\n",
        "fhalf_score = fbeta_score(y2_test, y2_pred_smn, beta=0.5)\n",
        "print(f\"F0.5 Score: {fhalf_score_smn}\")\n",
        "f2_score = fbeta_score(y2_test, y2_pred_smn, beta=2)\n",
        "print(f\"F2 Score: {f2_score_smn}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmlhYDFmlA1L"
      },
      "source": [
        "##### SVC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "n-zBIk3xlCWx",
        "outputId": "69b7b555-45f5-4240-c4f0-5719dab400bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "y\n",
            "1    25980\n",
            "0    25980\n",
            "Name: count, dtype: int64\n",
            "SVC Applied with RandomOverSampler: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.88      0.92     11124\n",
            "           1       0.27      0.58      0.37       876\n",
            "\n",
            "    accuracy                           0.85     12000\n",
            "   macro avg       0.62      0.73      0.64     12000\n",
            "weighted avg       0.91      0.85      0.88     12000\n",
            "\n",
            "F0.5 Score: 0.3020292590844738\n",
            "F2 Score: 0.47372316802368614\n",
            "y\n",
            "1    25980\n",
            "0    25980\n",
            "Name: count, dtype: int64\n",
            "SVC-SMOTE Applied: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.88      0.92     11124\n",
            "           1       0.27      0.58      0.37       876\n",
            "\n",
            "    accuracy                           0.86     12000\n",
            "   macro avg       0.62      0.73      0.64     12000\n",
            "weighted avg       0.91      0.86      0.88     12000\n",
            "\n",
            "F0.5 Score: 0.11003280481137233\n",
            "F2 Score: 0.3238133547868061\n",
            "y\n",
            "1    25369\n",
            "0    25369\n",
            "Name: count, dtype: int64\n",
            "SVC-SMOTE TOMEK Applied: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.88      0.92     11124\n",
            "           1       0.27      0.58      0.37       876\n",
            "\n",
            "    accuracy                           0.86     12000\n",
            "   macro avg       0.62      0.73      0.64     12000\n",
            "weighted avg       0.91      0.86      0.88     12000\n",
            "\n",
            "F0.5 Score: 0.10594543940024989\n",
            "F2 Score: 0.3157731398867251\n",
            "y\n",
            "1    22497\n",
            "0    17384\n",
            "Name: count, dtype: int64\n",
            "SVC-SMOTEEN Applied: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.83      0.89     11124\n",
            "           1       0.23      0.64      0.33       876\n",
            "\n",
            "    accuracy                           0.81     12000\n",
            "   macro avg       0.60      0.73      0.61     12000\n",
            "weighted avg       0.91      0.81      0.85     12000\n",
            "\n",
            "F0.5 Score: 0.23043766578249336\n",
            "F2 Score: 0.29000625912789485\n"
          ]
        }
      ],
      "source": [
        "# 1. Apply RandomUnderSampler\n",
        "ros = RandomOverSampler(sampling_strategy='minority', random_state=seed)\n",
        "X2_train_ros, y2_train_ros = ros.fit_resample(X2_train, y2_train)\n",
        "print(y2_train_ros.value_counts())\n",
        "\n",
        "# Initiate SVC\n",
        "svc_ros = SVC(random_state=seed)\n",
        "svc_ros.fit(X2_train_ros, y2_train_ros)\n",
        "y2_pred = svc_ros.predict(X2_test)\n",
        "print(f\"SVC Applied with RandomOverSampler: \\n\", classification_report(y2_test, y2_pred))\n",
        "# the result is skewed, since the data is imbalanced\n",
        "fhalf_score = fbeta_score(y2_test, y2_pred, beta=0.5)\n",
        "print(f\"F0.5 Score: {fhalf_score}\")\n",
        "f2_score = fbeta_score(y2_test, y2_pred, beta=2)\n",
        "print(f\"F2 Score: {f2_score}\")\n",
        "\n",
        "\n",
        "# 2. Apply SMOTE (Synthetic Minotiry Oversampling Technique)\n",
        "sm = SMOTE(sampling_strategy = 'minority', random_state=seed)\n",
        "X2_train_sm, y2_train_sm = sm.fit_resample(X2_train, y2_train)\n",
        "print(y2_train_sm.value_counts())\n",
        "# Initiating SGDClassifier\n",
        "svc_sm = SVC(random_state=seed)\n",
        "svc_sm.fit(X2_train_sm, y2_train_sm)\n",
        "y2_pred_sm = svc_sm.predict(X2_test)\n",
        "print(f\"SVC-SMOTE Applied: \\n\", classification_report(y2_test, y2_pred_sm))\n",
        "fhalf_score = fbeta_score(y2_test, y2_pred_sm, beta=0.5)\n",
        "print(f\"F0.5 Score: {fhalf_score_sm}\")\n",
        "f2_score = fbeta_score(y2_test, y2_pred_sm, beta=2)\n",
        "print(f\"F2 Score: {f2_score_sm}\")\n",
        "\n",
        "\n",
        "# 3. Apply SMOTE-TOMEK\n",
        "smt = SMOTETomek(sampling_strategy = 'minority', random_state=seed)\n",
        "X2_train_smt, y2_train_smt = smt.fit_resample(X2_train, y2_train)\n",
        "print(y2_train_smt.value_counts())\n",
        "# Initiating SVC\n",
        "svc_smt = SVC(random_state=seed)\n",
        "svc_smt.fit(X2_train_smt, y2_train_smt)\n",
        "y2_pred_smt = svc_smt.predict(X2_test)\n",
        "print(f\"SVC-SMOTE TOMEK Applied: \\n\", classification_report(y2_test, y2_pred_smt))\n",
        "fhalf_score = fbeta_score(y2_test, y2_pred_smt, beta=0.5)\n",
        "print(f\"F0.5 Score: {fhalf_score_smt}\")\n",
        "f2_score = fbeta_score(y2_test, y2_pred_smt, beta=2)\n",
        "print(f\"F2 Score: {f2_score_smt}\")\n",
        "\n",
        "# 4. Apply SMOTEEN to balance the classes\n",
        "smn = SMOTEENN(sampling_strategy = 'minority', random_state=seed)\n",
        "X2_train_smn, y2_train_smn = smn.fit_resample(X2_train, y2_train)\n",
        "print(y2_train_smn.value_counts())\n",
        "# Initiating SVC\n",
        "svc_smn = SVC(random_state=seed)\n",
        "svc_smn.fit(X2_train_smn, y2_train_smn)\n",
        "y2_pred_smn = svc_smn.predict(X2_test)\n",
        "print(f\"SVC-SMOTEEN Applied: \\n\", classification_report(y2_test, y2_pred_smn))\n",
        "fhalf_score = fbeta_score(y2_test, y2_pred_smn, beta=0.5)\n",
        "print(f\"F0.5 Score: {fhalf_score_smn}\")\n",
        "f2_score = fbeta_score(y2_test, y2_pred_smn, beta=2)\n",
        "print(f\"F2 Score: {f2_score_smn}\")\n",
        "\n",
        "\n",
        "# Somthing's wrong here:\n",
        "# For the 1st layer, I had a higher perforamcne with fewer features, but here, I train with many columns but!! having a lower performancce.\n",
        "# I should detect why - probably small mistakes!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9It-DpwlDSs"
      },
      "source": [
        "##### LGBMClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "P8PhbgKVlGId",
        "outputId": "cc4bf0bc-181d-48a2-8547-5792db840428"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "y\n",
            "1    25980\n",
            "0    25980\n",
            "Name: count, dtype: int64\n",
            "[LightGBM] [Info] Number of positive: 25980, number of negative: 25980\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003657 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 684\n",
            "[LightGBM] [Info] Number of data points in the train set: 51960, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "LGBMClassifier Applied with RandomOverSampler: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.87      0.92     11124\n",
            "           1       0.32      0.76      0.45       876\n",
            "\n",
            "    accuracy                           0.86     12000\n",
            "   macro avg       0.65      0.82      0.68     12000\n",
            "weighted avg       0.93      0.86      0.89     12000\n",
            "\n",
            "F0.5 Score: 0.35844797936371453\n",
            "F2 Score: 0.5943682053109962\n",
            "y\n",
            "1    25980\n",
            "0    25980\n",
            "Name: count, dtype: int64\n",
            "[LightGBM] [Info] Number of positive: 25980, number of negative: 25980\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007082 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 687\n",
            "[LightGBM] [Info] Number of data points in the train set: 51960, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "LGBM-SMOTE Applied: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.91      0.93     11124\n",
            "           1       0.32      0.55      0.40       876\n",
            "\n",
            "    accuracy                           0.88     12000\n",
            "   macro avg       0.64      0.73      0.67     12000\n",
            "weighted avg       0.92      0.88      0.89     12000\n",
            "\n",
            "F0.5 Score: 0.11003280481137233\n",
            "F2 Score: 0.3238133547868061\n",
            "y\n",
            "1    25369\n",
            "0    25369\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# 1. Apply RandomUnderSampler\n",
        "ros = RandomOverSampler(sampling_strategy='minority', random_state=seed)\n",
        "X2_train_ros, y1_train_ros = ros.fit_resample(X2_train, y2_train)\n",
        "print(y1_train_ros.value_counts())\n",
        "\n",
        "# Initiate LGBMClassifier\n",
        "lgbm_ros = LGBMClassifier(random_state=seed)\n",
        "lgbm_ros.fit(X2_train_ros, y2_train_ros)\n",
        "y2_pred = lgbm_ros.predict(X2_test)\n",
        "print(f\"LGBMClassifier Applied with RandomOverSampler: \\n\", classification_report(y2_test, y2_pred))\n",
        "# the result is skewed, since the data is imbalanced\n",
        "fhalf_score = fbeta_score(y2_test, y2_pred, beta=0.5)\n",
        "print(f\"F0.5 Score: {fhalf_score}\")\n",
        "f2_score = fbeta_score(y2_test, y2_pred, beta=2)\n",
        "print(f\"F2 Score: {f2_score}\")\n",
        "\n",
        "# 2. Apply SMOTE (Synthetic Minotiry Oversampling Technique)\n",
        "sm = SMOTE(sampling_strategy = 'minority', random_state=seed)\n",
        "X2_train_sm, y2_train_sm = sm.fit_resample(X2_train, y2_train)\n",
        "print(y2_train_sm.value_counts())\n",
        "# Initiating LGBMClassifier\n",
        "lgbm_sm = LGBMClassifier(random_state=seed)\n",
        "lgbm_sm.fit(X2_train_sm, y2_train_sm)\n",
        "y2_pred_sm = lgbm_sm.predict(X2_test)\n",
        "print(f\"LGBM-SMOTE Applied: \\n\", classification_report(y2_test, y2_pred_sm))\n",
        "fhalf_score = fbeta_score(y2_test, y2_pred_sm, beta=0.5)\n",
        "print(f\"F0.5 Score: {fhalf_score_sm}\")\n",
        "f2_score = fbeta_score(y2_test, y2_pred_sm, beta=2)\n",
        "print(f\"F2 Score: {f2_score_sm}\")\n",
        "\n",
        "# 3. Apply SMOTE-TOMEK\n",
        "smt = SMOTETomek(sampling_strategy = 'minority', random_state=seed)\n",
        "X2_train_smt, y2_train_smt = smt.fit_resample(X2_train, y2_train)\n",
        "print(y2_train_smt.value_counts())\n",
        "# Initiating LGBM\n",
        "lgbm_smt = SVC(random_state=seed)\n",
        "lgbm_smt.fit(X2_train_smt, y2_train_smt)\n",
        "y2_pred_smt = lgbm_smt.predict(X2_test)\n",
        "print(f\"LGBM-SMOTE TOMEK Applied: \\n\", classification_report(y2_test, y2_pred_smt))\n",
        "fhalf_score = fbeta_score(y2_test, y2_pred_smt, beta=0.5)\n",
        "print(f\"F0.5 Score: {fhalf_score_smt}\")\n",
        "f2_score = fbeta_score(y2_test, y2_pred_smt, beta=2)\n",
        "print(f\"F2 Score: {f2_score_smt}\")\n",
        "\n",
        "# 4. Apply SMOTEEN to balance the classes\n",
        "smn = SMOTEENN(sampling_strategy = 'minority', random_state=seed)\n",
        "X2_train_smn, y2_train_smn = smn.fit_resample(X2_train, y2_train)\n",
        "print(y2_train_smn.value_counts())\n",
        "# Initiating LGBM\n",
        "lgbm_smn = LGBMClassifier(random_state=seed)\n",
        "lgbm_smn.fit(X2_train_smn, y2_train_smn)\n",
        "y2_pred_smn = svc_smn.predict(X2_test)\n",
        "print(f\"LGBM-SMOTEEN Applied: \\n\", classification_report(y2_test, y2_pred_smn))\n",
        "fhalf_score = fbeta_score(y2_test, y2_pred_smn, beta=0.5)\n",
        "print(f\"F0.5 Score: {fhalf_score_smn}\")\n",
        "f2_score = fbeta_score(y2_test, y2_pred_smn, beta=2)\n",
        "print(f\"F2 Score: {f2_score_smn}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXkd8MLdlGfg"
      },
      "source": [
        "##### DecisionTreeClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AxMb8RmmlKDj"
      },
      "outputs": [],
      "source": [
        "# 1. Apply RandomUnderSampler\n",
        "ros = RandomOverSampler(sampling_strategy='minority', random_state=seed)\n",
        "X2_train_ros, y2_train_ros = ros.fit_resample(X2_train, y2_train)\n",
        "print(y2_train_ros.value_counts())\n",
        "\n",
        "# Initiate DecisionTreeClassifier\n",
        "dtc_ros = DecisionTreeClassifier(random_state=seed)\n",
        "dtc_ros.fit(X2_train_ros, y2_train_ros)\n",
        "y2_pred = dtc_ros.predict(X2_test)\n",
        "print(f\"DecisionTreeClassifier Applied with RandomOverSampler: \\n\", classification_report(y2_test, y2_pred))\n",
        "# the result is skewed, since the data is imbalanced\n",
        "fhalf_score = fbeta_score(y2_test, y2_pred, beta=0.5)\n",
        "print(f\"F0.5 Score: {fhalf_score}\")\n",
        "f2_score = fbeta_score(y2_test, y2_pred, beta=2)\n",
        "print(f\"F2 Score: {f2_score}\")\n",
        "\n",
        "\n",
        "# 2. Apply SMOTE (Synthetic Minotiry Oversampling Technique)\n",
        "sm = SMOTE(sampling_strategy = 'minority', random_state=seed)\n",
        "X2_train_sm, y2_train_sm = sm.fit_resample(X2_train, y2_train)\n",
        "print(y2_train_sm.value_counts())\n",
        "# Initiating DecisionTreeClassifier\n",
        "dtc_sm = DecisionTreeClassifier(random_state=seed)\n",
        "dtc_sm.fit(X2_train_sm, y2_train_sm)\n",
        "y2_pred_sm = dtc_sm.predict(X2_test)\n",
        "print(f\"DTC-SMOTE Applied: \\n\", classification_report(y2_test, y2_pred_sm))\n",
        "fhalf_score = fbeta_score(y2_test, y2_pred_sm, beta=0.5)\n",
        "print(f\"F0.5 Score: {fhalf_score_sm}\")\n",
        "f2_score = fbeta_score(y2_test, y2_pred_sm, beta=2)\n",
        "print(f\"F2 Score: {f2_score_sm}\")\n",
        "\n",
        "\n",
        "# 3. Apply SMOTE-TOMEK\n",
        "smt = SMOTETomek(sampling_strategy = 'minority', random_state=seed)\n",
        "X2_train_smt, y2_train_smt = smt.fit_resample(X2_train, y2_train)\n",
        "print(y2_train_smt.value_counts())\n",
        "# Initiating DecisionTreeClassifier\n",
        "dtc_smt = DecisionTreeClassifier(random_state=seed)\n",
        "dtc_smt.fit(X2_train_smt, y2_train_smt)\n",
        "y2_pred_smt = dtc_smt.predict(X2_test)\n",
        "print(f\"LGBM-SMOTE TOMEK Applied: \\n\", classification_report(y2_test, y2_pred_smt))\n",
        "fhalf_score = fbeta_score(y2_test, y2_pred_smt, beta=0.5)\n",
        "print(f\"F0.5 Score: {fhalf_score_smt}\")\n",
        "f2_score = fbeta_score(y2_test, y2_pred_smt, beta=2)\n",
        "print(f\"F2 Score: {f2_score_smt}\")\n",
        "\n",
        "\n",
        "# 4. Apply SMOTEEN to balance the classes\n",
        "smn = SMOTEENN(sampling_strategy = 'minority', random_state=seed)\n",
        "X2_train_smn, y2_train_smn = smn.fit_resample(X2_train, y2_train)\n",
        "print(y2_train_smn.value_counts())\n",
        "# Initiating DTC\n",
        "dtc_smn = DecisionTreeClassifier(random_state=seed)\n",
        "dtc_smn.fit(X2_train_smn, y2_train_smn)\n",
        "y2_pred_smn = dtc_smn.predict(X2_test)\n",
        "print(f\"DTC-SMOTEEN Applied: \\n\", classification_report(y2_test, y2_pred_smn))\n",
        "fhalf_score = fbeta_score(y2_test, y2_pred_smn, beta=0.5)\n",
        "print(f\"F0.5 Score: {fhalf_score_smn}\")\n",
        "f2_score = fbeta_score(y2_test, y2_pred_smn, beta=2)\n",
        "print(f\"F2 Score: {f2_score_smn}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ON0n2zztLDm"
      },
      "source": [
        "### Applying OpTuna on SVC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "VpoZ7DzEtIwc"
      },
      "outputs": [],
      "source": [
        "import optuna\n",
        "from optuna import Trial\n",
        "from optuna.samplers import TPESampler\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.datasets import make_classification  # Replace with your own data\n",
        "\n",
        "# Define the objective function for Optuna\n",
        "def objective(trial: Trial):\n",
        "    # Suggest hyperparameters for SVC\n",
        "    C = trial.suggest_loguniform('C', 1e-3, 1e3)  # Regularization parameter\n",
        "    gamma = trial.suggest_loguniform('gamma', 1e-4, 1e1)  # Kernel coefficient\n",
        "    kernel = trial.suggest_categorical('kernel', ['rbf', 'poly', 'sigmoid'])  # Kernel type\n",
        "\n",
        "    # Create an SVC model pipeline\n",
        "    model = Pipeline([\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('svc', SVC(C=C, gamma=gamma, kernel=kernel, random_state=seed))\n",
        "    ])\n",
        "\n",
        "    # Use StratifiedKFold for better class balance in cross-validation\n",
        "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
        "    scores = cross_val_score(model, X2_train_smn, y2_train_smn, cv=skf, scoring='accuracy')\n",
        "\n",
        "    # Return the average cross-validation score\n",
        "    return scores.mean()\n",
        "\n",
        "# Create an Optuna study and optimize it\n",
        "study = optuna.create_study(direction='maximize', sampler=TPESampler())\n",
        "study.optimize(objective, n_trials=50)  # Adjust 'n_trials' as needed\n",
        "\n",
        "# Print the best trial's parameters and score\n",
        "print(f\"Best trial score: {study.best_trial.value}\")\n",
        "print(f\"Best trial parameters: {study.best_params}\")\n",
        "\n",
        "# Train the SVC with the best parameters on the resampled training data\n",
        "best_params = study.best_params\n",
        "best_svc = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('svc', SVC(C=best_params['C'], gamma=best_params['gamma'], kernel=best_params['kernel'], random_state=seed))\n",
        "])\n",
        "best_svc.fit(X2_train_smn, y2_train_smn)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y2_pred_smn = best_svc.predict(X2_test)\n",
        "\n",
        "# Print the classification report\n",
        "print(\"SVC-SMOTEEN Applied with Best Parameters:\")\n",
        "print(classification_report(y2_test, y2_pred_smn))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDs1Cp37mSPC"
      },
      "source": [
        "### 3rd Layer: Training, help the company understand who those customers are\n",
        "\n",
        "- do not use standardscaler, because I will loose interpretability (hard to understand the values)\n",
        "- try to print out average/ median for each clusters,\n",
        "features I will be print out would be age, durations, jobs for these customers.\n",
        "- filter out non subscribers and only work with subscribers\n",
        "- unsupversied training K-means and hierarchical clustering to identify customer segments, only the subscribers\n",
        "- After I finish K-means and h clusters dimensionality reduction techniques PCA, TSNE, U-Map (just for the visualization purposes) for 2d and 3d\n",
        "- If I can, send a thank you email to Zeyneb (I did)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9NB23Wv1Tou"
      },
      "source": [
        "#### K-Means and PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MOvqKyFJsEJ8"
      },
      "outputs": [],
      "source": [
        "# Step1: Filter the data to include only subscribers.\n",
        "subscribers_data = df_copy[df_copy['y']==1]  # Assuming 'y' is the column indicating subscribers\n",
        "# subscribers_data  # 2896\n",
        "\n",
        "\n",
        "# Step 2: Select relevant features for clustering\n",
        "# Exclude 'y' and other call-related features like 'duration', 'campaign', etc.\n",
        "clustering_features = subscribers_data.drop(columns=['y', 'duration', 'campaign', 'day', 'month'])\n",
        "# clustering_features  # 2896\n",
        "\n",
        "\n",
        "# Step 3: Scale the data\n",
        "# StandardScaler = StandardScaler()\n",
        "# scaled_features = StandardScaler.fit_transform(clustering_features)\n",
        "# scaled_features\n",
        "\n",
        "# Step 4: Apply KMeans Clustering\n",
        "# Determine optimal number of clusters using the elbow method\n",
        "wcss = []  # Within-cluster sum of squares\n",
        "for i in range(1, 11):\n",
        "    kmeans = KMeans(n_clusters=i, random_state=seed)\n",
        "    kmeans.fit(scaled_features)\n",
        "    wcss.append(kmeans.inertia_)\n",
        "\n",
        "plt.plot(range(1, 11), wcss)\n",
        "plt.title('Elbow Method')\n",
        "plt.xlabel('Number of clusters')\n",
        "plt.ylabel('WCSS')\n",
        "plt.show()\n",
        "\n",
        "# Choose the number of clusters (e.g., 3) based on the elbow plot\n",
        "optimal_clusters = 3\n",
        "kmeans = KMeans(n_clusters=optimal_clusters, random_state=seed)\n",
        "subscribers_data['Cluster'] = kmeans.fit_predict(scaled_features)\n",
        "\n",
        "\n",
        "# Step 5: Analyze and interpret the clusters\n",
        "# For example, checking the distribution of each cluster:\n",
        "print(subscribers_data['Cluster'].value_counts())\n",
        "\n",
        "# Or calculating the mean values of each feature within clusters to understand characteristics:\n",
        "cluster_summary = subscribers_data.groupby('Cluster').mean()\n",
        "# For Ordinal Feature:\n",
        "# Job/Education etc.. Feature: try to calculate the most common and include that separately unless it makse hard for me to interpret the data\n",
        "print(cluster_summary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xztbEE2s0sMc"
      },
      "outputs": [],
      "source": [
        "# If needed, visualize the clusters using PCA (Principal Component Analysis) for better understanding:\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA(n_components=2)\n",
        "pca_components = pca.fit_transform(scaled_features)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(pca_components[:, 0], pca_components[:, 1], c=subscribers_data['Cluster'], cmap='viridis')\n",
        "plt.title('Customer Segmentation using KMeans')\n",
        "plt.xlabel('PCA Component 1')\n",
        "plt.ylabel('PCA Component 2')\n",
        "plt.colorbar(label='Cluster')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Ph7EseM71dj"
      },
      "source": [
        "#### K-Means"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p_OGtgqQ4kby"
      },
      "outputs": [],
      "source": [
        "# Step 1: Filter the data to include only subscribers\n",
        "subscribers_data = df_copy[df_copy['y'] == 1]  # Assuming 'y' is the column indicating subscription status\n",
        "\n",
        "# Step 2: Select relevant features for clustering\n",
        "# Exclude 'y' and other call-related features like 'duration', 'campaign', 'day', 'month'\n",
        "clustering_features = subscribers_data.drop(columns=['y', 'duration', 'campaign', 'day', 'month'])\n",
        "\n",
        "# Step 3: Scale the data\n",
        "scaler = StandardScaler()\n",
        "scaled_features = scaler.fit_transform(clustering_features)\n",
        "\n",
        "# Step 4: Apply KMeans Clustering\n",
        "# Determine the optimal number of clusters using the elbow method (optional)\n",
        "wcss = []  # Within-cluster sum of squares\n",
        "for i in range(1, 11):\n",
        "    kmeans = KMeans(n_clusters=i, random_state=42)\n",
        "    kmeans.fit(scaled_features)\n",
        "    wcss.append(kmeans.inertia_)\n",
        "\n",
        "plt.plot(range(1, 11), wcss)\n",
        "plt.title('Elbow Method')\n",
        "plt.xlabel('Number of clusters')\n",
        "plt.ylabel('WCSS')\n",
        "plt.show()\n",
        "\n",
        "# Choose the number of clusters (e.g., 3) based on the elbow plot\n",
        "optimal_clusters = 3\n",
        "kmeans = KMeans(n_clusters=optimal_clusters, random_state=42)\n",
        "subscribers_data['Cluster'] = kmeans.fit_predict(scaled_features)\n",
        "\n",
        "# Step 5: Analyze and interpret the clusters\n",
        "print(subscribers_data['Cluster'].value_counts())\n",
        "\n",
        "# Calculate the mean values of each feature within clusters to understand characteristics\n",
        "cluster_summary = subscribers_data.groupby('Cluster').mean()\n",
        "print(cluster_summary)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SH93jjPq79TE"
      },
      "source": [
        "#### Hierarhical Clustering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ozH9HtTI4uCS"
      },
      "outputs": [],
      "source": [
        "# Step 1: Filter the data to include only subscribers\n",
        "subscribers_data = df_copy[df_copy['y'] == 1]  # Assuming 'y' is the column indicating subscription status\n",
        "\n",
        "# Step 2: Select relevant features for clustering\n",
        "# Exclude 'y' and other call-related features like 'duration', 'campaign', 'day', 'month'\n",
        "clustering_features = subscribers_data.drop(columns=['y', 'duration', 'campaign', 'day', 'month'])\n",
        "\n",
        "# Step 3: Scale the data\n",
        "scaler = StandardScaler()\n",
        "scaled_features = scaler.fit_transform(clustering_features)\n",
        "\n",
        "# Step 4: Apply Hierarchical Clustering\n",
        "# Create the linkage matrix using 'ward' method\n",
        "linked = linkage(scaled_features, method='ward')\n",
        "\n",
        "# Plot the dendrogram to determine the optimal number of clusters\n",
        "plt.figure(figsize=(10, 7))\n",
        "dendrogram(linked)\n",
        "plt.title('Dendrogram')\n",
        "plt.xlabel('Samples')\n",
        "plt.ylabel('Euclidean distances')\n",
        "plt.show()\n",
        "\n",
        "# Cut the dendrogram at a point to define clusters, e.g., 3 clusters\n",
        "optimal_clusters = 3\n",
        "hierarchical = AgglomerativeClustering(n_clusters=optimal_clusters, linkage='ward')\n",
        "subscribers_data['Cluster'] = hierarchical.fit_predict(scaled_features)\n",
        "\n",
        "# Step 5: Analyze and interpret the clusters\n",
        "print(subscribers_data['Cluster'].value_counts())\n",
        "# But I don't know what each values means\n",
        "\n",
        "# Calculate the mean values of each feature within clusters to understand characteristics\n",
        "cluster_summary = subscribers_data.groupby('Cluster').mean()\n",
        "print(cluster_summary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "clFFhnst_cnN"
      },
      "outputs": [],
      "source": [
        "# Step 1: Filter out non-subscribers (only keep customers who have purchased the product)\n",
        "subscribers_df = df_copy[df_copy['y'] == 1]\n",
        "\n",
        "# Step 2: Select features for clustering (you can adjust these based on relevance)\n",
        "features = ['age', 'balance', 'duration', 'campaign']  # Example features\n",
        "X = subscribers_df[features]\n",
        "\n",
        "# Step 3: Scale the features\n",
        "scaler = StandardScaler()\n",
        "scaled_features = scaler.fit_transform(X)\n",
        "\n",
        "# Step 4: Determine the optimal number of clusters using the elbow method\n",
        "wcss = []\n",
        "for i in range(1, 11):\n",
        "    kmeans = KMeans(n_clusters=i, random_state=42)\n",
        "    kmeans.fit(scaled_features)\n",
        "    wcss.append(kmeans.inertia_)\n",
        "\n",
        "# Plot the Elbow Method\n",
        "plt.plot(range(1, 11), wcss)\n",
        "plt.title('Elbow Method for Optimal k')\n",
        "plt.xlabel('Number of clusters')\n",
        "plt.ylabel('WCSS')\n",
        "plt.show()\n",
        "\n",
        "# Step 5: Apply K-means with the chosen number of clusters (e.g., k=3 based on elbow plot)\n",
        "kmeans = KMeans(n_clusters=3, random_state=42)\n",
        "subscribers_df['cluster'] = kmeans.fit_predict(scaled_features)\n",
        "\n",
        "# Step 6: Analyze the clusters\n",
        "# Get the mean values of each feature for each cluster to understand their characteristics\n",
        "cluster_summary = subscribers_df.groupby('cluster')[features].mean()\n",
        "print(cluster_summary)\n",
        "\n",
        "# Step 7: Visualize the segments\n",
        "# This can be done using bar plots, scatter plots, etc.\n",
        "# For example, to see how 'balance' and 'duration' differ across clusters:\n",
        "sns.boxplot(x='cluster', y='balance', data=subscribers_df)\n",
        "plt.title('Balance Distribution Across Clusters')\n",
        "plt.show()\n",
        "\n",
        "sns.boxplot(x='cluster', y='duration', data=subscribers_df)\n",
        "plt.title('Duration Distribution Across Clusters')\n",
        "plt.show()\n",
        "\n",
        "# 1. Cluster 0:\n",
        "# Median Balance: The median balance is relatively low compared to the other clusters.\n",
        "# Balance Range: The interquartile range (IQR) is small, indicating less variability in balances within this cluster.\n",
        "# Potential Insight: Customers in this cluster have lower balances, which could mean they might be less likely to invest large amounts or prefer smaller deposits. They might need more encouragement to invest.\n",
        "\n",
        "# 2. Cluster 1:\n",
        "# Median Balance: The median balance is the highest among all clusters.\n",
        "# Balance Range: The IQR is wider, meaning there's a larger spread of balances among customers in this cluster. The balance is generally high.\n",
        "# Potential Insight: This cluster represents customers with higher balances, which makes them potentially valuable targets for investment products. They might have more disposable income and could be more willing to invest in higher-value products.\n",
        "\n",
        "# 3. Cluster 2:\n",
        "# Median Balance: This cluster has a median balance between Cluster 0 and Cluster 1.\n",
        "# Balance Range: There is a moderate spread in the balances, with some outliers on the higher end.\n",
        "# Potential Insight: Customers in this cluster have moderate balances but could have a few individuals who are potentially high-value investors. They might be interested in products with medium-term returns or might need targeted offers to convert."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "9Ph7EseM71dj",
        "SH93jjPq79TE"
      ],
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyOZuWdaEIyywp3o1udn8aZA",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}